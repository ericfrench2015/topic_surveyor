{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518c1217-c681-47b8-93f5-c50b58db3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08c61a1-a235-455f-be1b-abaf95374dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief_web_urls = ['https://reliefweb.int/disaster/eq-2023-000015-tur'\n",
    "                   ,'https://reliefweb.int/disaster/dr-2021-000022-afg'\n",
    "                   ,'https://reliefweb.int/disaster/ff-2023-000133-afg'\n",
    "                   ,'https://reliefweb.int/disaster/eq-2023-000184-afg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf435e8-ea07-478e-97d4-b54f46a03664",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(relief_web_urls[0])\n",
    "html = res.text\n",
    "soup = BeautifulSoup(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abcf46-d8d8-4a88-9276-5474fe25f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "<meta property=\"og:title\" content=\"Afghanistan: Earthquakes - Oct 2023\" />\\n\n",
    "<meta property=\"og:description\" content=\"Humanitarian situation reports, response plans, news, analyses, evaluations, assessments, maps, infographics and more on Afghanistan: Earthquakes - Oct 2023\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c9815b-0bc2-406d-a08e-4356112eae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief_web_fields = {\n",
    "    'Disaster Description' : ['h2',{'class': 'cd-block-title rw-entity-text__title', 'id': 'overview-title'}]\n",
    "    ,'glide' : ['dd',{'class':'rw-entity-meta__tag-value rw-entity-meta__tag-value--glide rw-entity-meta__tag-value--simple rw-entity-meta__tag-value--last'}]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c17510d-a389-4bf0-92ce-452c8c848064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EQ-2023-000015-TUR']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_discrete_tag_text(soup, tag, attributes={}):\n",
    "    results = soup.find_all(tag, attributes)\n",
    "    r_list=[]\n",
    "    for r in results:\n",
    "        r_list.append(r.text.strip())\n",
    "    return r_list\n",
    "\n",
    " \n",
    "tag = 'dd'\n",
    "attributes = {}\n",
    "attributes = {'class':'rw-entity-meta__tag-value rw-entity-meta__tag-value--glide rw-entity-meta__tag-value--simple rw-entity-meta__tag-value--last'}\n",
    "\n",
    "get_discrete_tag_text(soup, relief_web_fields['glide'][0], attributes = relief_web_fields['glide'][1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#<dd class=\"rw-entity-meta__tag-value--status--ongoing rw-entity-meta__tag-value rw-entity-meta__tag-value--status rw-entity-meta__tag-value--simple\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f338bd8-1757-4b33-a2c8-8ae3ead1f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan']\n"
     ]
    }
   ],
   "source": [
    "# Find all <a> tags (links) in the HTML\n",
    "links = soup.find_all('a')\n",
    "\n",
    "#this gets the desc\n",
    "target_tag = soup.find('h2', {'class': 'cd-block-title rw-entity-text__title', 'id': 'overview-title'})\n",
    "\n",
    "\n",
    "def extract_metadata(soup):\n",
    "    #get title\n",
    "    meta_tags = soup.find_all('meta')  # Find all <meta> tags in the HTML content\n",
    "\n",
    "    # Extract content from specific <meta> tags using their property attribute\n",
    "    for tag in meta_tags:\n",
    "        if tag.get('property') == 'og:title':\n",
    "            title = tag.get('content')\n",
    "            #print(f\"og:title content: {title}\")\n",
    "        elif tag.get('property') == 'og:description':\n",
    "            description = tag.get('content')\n",
    "            #print(f\"og:description content: {description}\")\n",
    "\n",
    "    return title, description\n",
    "    \n",
    "title, description = extract_metadata(soup)\n",
    "#print(title, description)\n",
    "\n",
    "def extract_affected_countries(soup):\n",
    "    # Find all <h3> tags with class 'rw-river-article__title'\n",
    "    countries_section = soup.find('section', id='countries')\n",
    "    \n",
    "    # Find all <h3> tags with class 'rw-river-article__title' within the 'countries' section\n",
    "    country_titles = countries_section.find_all('h3', class_='rw-river-article__title')\n",
    "    \n",
    "    countries = []\n",
    "    for title in country_titles:\n",
    "        country_name = title.text.strip()\n",
    "        countries.append(country_name)\n",
    "    \n",
    "    return countries\n",
    "\n",
    "x = extract_affected_countries(soup)\n",
    "print(x)\n",
    "\n",
    "def extract_content(soup):\n",
    "    #this gets the full text content\n",
    "    target_tag = soup.find('div', {'class': 'rw-entity-text__content', 'id': 'overview-content'})\n",
    "    \n",
    "    #within the text content, take it paragraphy by paragraph\n",
    "    if target_tag:\n",
    "        content=[]\n",
    "        paras = target_tag.find_all('p')\n",
    "        for p in paras:\n",
    "            links = p.find_all('a')  # Find all <a> tags within each <p> tag\n",
    "            l=[]\n",
    "            for link in links:\n",
    "                href = link.get('href')  # Get the 'href' attribute from each <a> tag\n",
    "\n",
    "                l.append(href)\n",
    "\n",
    "            #if there are no urls, set to None so fillna can deal with it later\n",
    "            if len(l) == 0:\n",
    "                l = None\n",
    "            content.append([p.text.strip(),l])\n",
    "    return content\n",
    "\n",
    "\n",
    "#x = extract_content(soup)\n",
    "#x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb21abd2-95f5-4e91-836c-cd716675fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://reliefweb.int/disaster/eq-2023-000015-tur\n",
      "https://reliefweb.int/disaster/dr-2021-000022-afg\n",
      "https://reliefweb.int/disaster/ff-2023-000133-afg\n",
      "https://reliefweb.int/disaster/eq-2023-000184-afg\n"
     ]
    }
   ],
   "source": [
    "#load text to df\n",
    "df_reliefweb_disaster_summary = pd.DataFrame(columns = ['record_type','source_url','glide_id','source_level_country','source_title','source_desc','source_original_text','reference_url'])\n",
    "for url in relief_web_urls:\n",
    "    print (url)\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "\n",
    "    glide_id = get_discrete_tag_text(soup, relief_web_fields['glide'][0], attributes = relief_web_fields['glide'][1])[0]\n",
    "\n",
    "    title, description = extract_metadata(soup)\n",
    "    countries_affected = extract_affected_countries(soup)\n",
    "    content = extract_content(soup)\n",
    "\n",
    "    for c in content:\n",
    "        row = ['disaster summary',url,glide_id,countries_affected,title,description,]\n",
    "        row.extend(c)\n",
    "        df_reliefweb_disaster_summary.loc[len(df_reliefweb_disaster_summary)] = row\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "056880df-3a83-4753-8f53-f2d868122f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text             is expected to increase in the coming days/weeks.\n",
       "source                                                   OCHA asdf\n",
       "reported_date                                          16 Feb 2023\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_reliefweb_summary_reference(text):\n",
    "    # reliefweb disaster summary text ends with a parenthetical reference to a detailed source.\n",
    "    # this function finds and extracts them\n",
    "    \n",
    "    #find (OHCA, 16 Feb 2023) - \n",
    "    #    but within that, find specifically 'OHCA' and '16 Feb 2023'\n",
    "    #    groups 2 and 3 respectively\n",
    "    source_and_date = re.search(r'\\((([\\w\\s]+), (\\d+ \\w+ \\d{4}))\\)$', text)\n",
    "    \n",
    "    if source_and_date:\n",
    "        source = source_and_date.group(2)\n",
    "        reported_date = source_and_date.group(3)\n",
    "    \n",
    "        #now that we have the metadata in hand, remove if from the source\n",
    "        text = text[:source_and_date.span()[0]].strip()\n",
    "        \n",
    "    else:\n",
    "        source = None\n",
    "        reported_date = None\n",
    "    \n",
    "    return pd.Series({'text':text, 'source':source, 'reported_date':reported_date})\n",
    "\n",
    "\n",
    "extract_reliefweb_summary_reference('is expected to increase in the coming days/weeks. (OCHA asdf, 16 Feb 2023)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60c88d39-f4ad-4a9e-a1f3-56a3994b1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reliefweb_disaster_summary[['text','authoring_org','reported_date']] = df_reliefweb_disaster_summary['source_original_text'].apply(extract_reliefweb_summary_reference)\n",
    "df_reliefweb_disaster_summary[['reference_url','authoring_org','reported_date']] = df_reliefweb_disaster_summary[['reference_url','authoring_org','reported_date']].bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc319376-553f-42bf-89c1-7129666c294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reliefweb_disaster_summary.to_csv(\"c://temp//foo.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e55f041-56a0-47e9-9e3a-a914b9e14f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_type</th>\n",
       "      <th>source_url</th>\n",
       "      <th>glide_id</th>\n",
       "      <th>source_level_country</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_desc</th>\n",
       "      <th>source_original_text</th>\n",
       "      <th>reference_url</th>\n",
       "      <th>text</th>\n",
       "      <th>authoring_org</th>\n",
       "      <th>reported_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>disaster summary</td>\n",
       "      <td>https://reliefweb.int/disaster/eq-2023-000015-tur</td>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>[Syrian Arab Republic, Türkiye]</td>\n",
       "      <td>Türkiye/Syria: Earthquakes - Feb 2023</td>\n",
       "      <td>Humanitarian situation reports, response plans...</td>\n",
       "      <td>Humanitarian needs remain 100 days after devas...</td>\n",
       "      <td>[https://reliefweb.int/node/3963175/]</td>\n",
       "      <td>Humanitarian needs remain 100 days after devas...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>17 May 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>disaster summary</td>\n",
       "      <td>https://reliefweb.int/disaster/eq-2023-000015-tur</td>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>[Syrian Arab Republic, Türkiye]</td>\n",
       "      <td>Türkiye/Syria: Earthquakes - Feb 2023</td>\n",
       "      <td>Humanitarian situation reports, response plans...</td>\n",
       "      <td>To date, partners have directly provided 4 mil...</td>\n",
       "      <td>[https://reliefweb.int/node/3963175/]</td>\n",
       "      <td>To date, partners have directly provided 4 mil...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>17 May 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         record_type                                         source_url  \\\n",
       "21  disaster summary  https://reliefweb.int/disaster/eq-2023-000015-tur   \n",
       "22  disaster summary  https://reliefweb.int/disaster/eq-2023-000015-tur   \n",
       "\n",
       "              glide_id             source_level_country  \\\n",
       "21  EQ-2023-000015-TUR  [Syrian Arab Republic, Türkiye]   \n",
       "22  EQ-2023-000015-TUR  [Syrian Arab Republic, Türkiye]   \n",
       "\n",
       "                             source_title  \\\n",
       "21  Türkiye/Syria: Earthquakes - Feb 2023   \n",
       "22  Türkiye/Syria: Earthquakes - Feb 2023   \n",
       "\n",
       "                                          source_desc  \\\n",
       "21  Humanitarian situation reports, response plans...   \n",
       "22  Humanitarian situation reports, response plans...   \n",
       "\n",
       "                                 source_original_text  \\\n",
       "21  Humanitarian needs remain 100 days after devas...   \n",
       "22  To date, partners have directly provided 4 mil...   \n",
       "\n",
       "                            reference_url  \\\n",
       "21  [https://reliefweb.int/node/3963175/]   \n",
       "22  [https://reliefweb.int/node/3963175/]   \n",
       "\n",
       "                                                 text authoring_org  \\\n",
       "21  Humanitarian needs remain 100 days after devas...          OCHA   \n",
       "22  To date, partners have directly provided 4 mil...          OCHA   \n",
       "\n",
       "   reported_date  \n",
       "21   17 May 2023  \n",
       "22   17 May 2023  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reliefweb_disaster_summary.loc[21:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebaab16-3edf-4150-a974-34b409fa4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "params = {\n",
    "    'appname': 'amcross',  \n",
    "    'profile': 'full',\n",
    "    'preset': 'latest',\n",
    "    'limit': 3,\n",
    "    'query[fields][]':'format.name',\n",
    "    'query[value]':'Situation Report',\n",
    "    'fields[include][]':['source.shortname',\"format\",\"body-html\"]\n",
    "}\n",
    "\n",
    "\n",
    "api_endpoint = 'https://api.reliefweb.int/v1/reports?appname=amcross'\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(api_endpoint, params=params)\n",
    "\n",
    "# Check the status of the response\n",
    "if response.status_code == 200:\n",
    "    # Parse and use the response data (in JSON format)\n",
    "    data = response.json()\n",
    "    situation_reports = data['data']\n",
    "    \n",
    "    # Process the situation reports as needed\n",
    "    for report in situation_reports:\n",
    "        # Extract relevant information from each report\n",
    "        #report_title = report['fields']['title']\n",
    "\n",
    "\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7a7f8-f6e9-4ae4-a56a-41d3678e4b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
