{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac893dee-0a35-4080-9773-5a062ada0fbf",
   "metadata": {},
   "source": [
    "# Begin the actual NLP work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbeab91-739d-44c0-81f2-8b9c0949756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from textacy import extract\n",
    "\n",
    "from collections import defaultdict \n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fe76aa-6c4d-4875-a536-5844ebfef3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitrep_preprocessed_file = \"D://projects//_external_files//surveyor//rw_sitrep_preprocessed//sitrep_preprocessed_b41b8e78f66d4e669917ea831f438b73.xlsx\"\n",
    "pcode_file = \"D://projects//_external_files//cod_files//combined_locations//locations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a3e83d-ff47-4daf-87da-40eb2aa1e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=12, tm_mday=17, tm_hour=6, tm_min=11, tm_sec=53, tm_wday=6, tm_yday=351, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf7f39-a913-4dd3-a11b-1ed061a3d279",
   "metadata": {},
   "source": [
    "## Load Location Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b633cc73-ea46-43ea-a45c-462c0190c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.read_csv(pcode_file)\n",
    "\n",
    "def get_pcode_from_location(loc, country_prefix='XX', lang_code='all'):\n",
    "\n",
    "    if country_prefix != 'XX': #if the country prefix is set, limit search to that\n",
    "        df_loc = df_location[df_location['pcode_prefix'] == country_prefix]\n",
    "    else:\n",
    "        df_loc = df_location\n",
    "\n",
    "    if lang_code != 'all': #secondary filter - especially important to remove dupes with diff langs share the same script\n",
    "        df_loc = df_loc[df_loc['lang_code'] == lang_code]\n",
    "        \n",
    "    matches = df_loc['pcode'][df_loc['location_name'].str.lower() == loc.lower()].tolist()\n",
    "\n",
    "    #if the match fails, try again on the normalized name\n",
    "    if len(matches) == 0:\n",
    "        #remove common variations in names that can cause misses\n",
    "        n_loc = re.sub(r'[^a-zA-Z]', '', loc)\n",
    "\n",
    "        #this will cause problems for non-English.. so if then len is 0, exit\n",
    "        if len(n_loc) == 0:\n",
    "            return []\n",
    "            \n",
    "        matches = df_loc['pcode'][df_loc['location_normalized'].str.lower() == n_loc.lower()].tolist()\n",
    "        \n",
    "\n",
    "    #now check results\n",
    "    if len(matches) > 1:\n",
    "        #print(f\"more than 1 matches... likely due to different granularity of entities with the same name (ie. Herat City in Herat Province) {matches}\")\n",
    "        #print(f\"returning the lowest granularity match. {min(matches, key=len)}\")\n",
    "        #print(\"if the pcodes are all the same granularity.... you get the first element.\")\n",
    "        return min(matches, key=len)\n",
    "            \n",
    "        return matches[0]\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "\n",
    "    else:\n",
    "        #couldn't find a match, do a fuzzy search\n",
    "        compare_list = list(set(df_loc['location_name'].tolist()))\n",
    "        possible_matches=[]\n",
    "        for i in compare_list:\n",
    "            if fuzz.ratio(loc,i) > 70:\n",
    "                possible_matches.append(i)\n",
    "                print (f\"No exact match to '{loc}'. see if these alternative spellings are correct: {possible_matches}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "assert get_pcode_from_location('istanbul') == 'TUR034'\n",
    "\n",
    "def get_adm_lvl_from_pcode(pcode):\n",
    "    return list(set(df_location['adm_lvl'][df_location['pcode'] == pcode].tolist()))\n",
    "    \n",
    "def get_name_in_lang(pcode, lang='en'):\n",
    "    return list(set(df_location['location_name'][(df_location['pcode'] == pcode) & (df_location['lang_code'] == lang)].tolist()))\n",
    "\n",
    "def get_descendents_of(pcode, lang='en', include_self=True):\n",
    "    if include_self==True:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)]\n",
    "    else:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)\\\n",
    "        & (df_location['pcode'] != pcode)]\n",
    "\n",
    "def get_admin_chain(pcode, lang='en'):\n",
    "    split_pcode = df_location['split_pcode'][df_location['pcode'] == pcode].tolist()[0]\n",
    "    levels = split_pcode.split(\".\")\n",
    "    pc =''\n",
    "    admin_chain = []\n",
    "    #rebuild the pcode one level at a time\n",
    "    for i in levels:\n",
    "        pc = pc + i\n",
    "        admin_chain.append(df_location['location_name'][(df_location['pcode'] == pc) & (df_location['lang_code'] == lang)].tolist()[0])\n",
    "\n",
    "    return admin_chain\n",
    "\n",
    "def get_all_locations(lang_code='all'):\n",
    "\n",
    "    #return all unique location names\n",
    "    if lang_code == 'all':\n",
    "        return list(set(df_location['location_name'].to_list()))\n",
    "    else:\n",
    "        return list(set(df_location['location_name'][df_location['lang_code'] == lang_code].to_list()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be425ff0-6307-4bc1-ad74-6de9f333155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create patterns and add to the entity ruler to better find locations\n",
    "\n",
    "all_locs = get_all_locations(lang_code='en')\n",
    "gpes = []\n",
    "\n",
    "STOP_LOCS = ['of','can']\n",
    "all_locs = [e for e in all_locs if e.lower() not in STOP_LOCS]\n",
    "\n",
    "# create pattern rules for locations based on the COD files\n",
    "for l in all_locs:\n",
    "    token_sequence=[]\n",
    "    for token in l.split('\\s+'):\n",
    "        token_sequence.append({\"LOWER\":token.lower()})\n",
    "    x = {'label':'COD_GPE', 'pattern': token_sequence, 'id':get_pcode_from_location(l, lang_code='en')[0]}\n",
    "    gpes.append(x)\n",
    "    #print(get_pcode_from_location(l, lang_code='en'))\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "ruler.add_patterns(gpes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d7ef1-036d-49de-b06e-136144e2c689",
   "metadata": {},
   "source": [
    "## Build the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b10233-5b6b-4653-93e7-09e04540a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel(sitrep_preprocessed_file)\n",
    "df = df.fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25928a77-590b-449a-acb4-65e90cdd770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EQ-2023-000015-TUR'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrow the scope for easier testing\n",
    "df = df[(df['glide_id'] == 'EQ-2023-000015-TUR') | (df['glide_id'] == 'EQ-2023-000214-NPL')]\n",
    "df = df[(df['glide_id'] == 'EQ-2023-000015-TUR')] # | (df['glide_id'] == 'EQ-2023-000214-NPL')]\n",
    "set(df['glide_id'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502c73b3-663a-4278-9589-24fee6911212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    #print()\n",
    "    #print(doc)\n",
    "    for sent in doc.sents:\n",
    "        #print(sent)\n",
    "        #create new doc objects for each sentence and append to a list\n",
    "        doc_from_span = spacy.tokens.Doc(doc.vocab, words=[token.text for token in sent])\n",
    "        sentences.append(doc_from_span)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        sent_text = sent.text\n",
    "        if len(sent_text) > 20:\n",
    "            sentences.append(nlp(sent_text)) # horrendously inefficient but...\n",
    "    if len(sentences) == 0:\n",
    "        sentences.append(nlp(\"No content to return.\"))\n",
    "    return sentences\n",
    "\n",
    "# Function to increment by one for each idx_parad\n",
    "def generate_sent_id(group, new_column_name='idx_sent'):\n",
    "    group[new_column_name] = range(0, len(group))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d10554-b22d-4688-9efa-8aeedc70086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_type', 'source_url', 'glide_id', 'idx_para',\n",
       "       'source_level_country', 'source_title', 'source_desc',\n",
       "       'source_original_text', 'reference_url', 'text', 'authoring_org',\n",
       "       'reported_date', 'para_id', 'non_parenthetical_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d6fe14-e59c-446d-ad86-5d5de365f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on ongoing for nowd\n",
    "df_sents = df.copy()\n",
    "df_sents['spacy_para_no_paren'] = df_sents['non_parenthetical_text'].apply(lambda x: nlp(x))\n",
    "df_sents['spacy_sent_no_paren'] = df_sents['spacy_para_no_paren'].apply(expand_to_sentence_level)\n",
    "df_sents = df_sents.explode('spacy_sent_no_paren')\n",
    "\n",
    "# Apply the function to the DataFrame using groupby on 'idx_para'\n",
    "df_sents = df_sents.groupby(['para_id','idx_para']).apply(generate_sent_id).reset_index(drop=True)\n",
    "\n",
    "#to limit the fields but this just seems to cause problems\n",
    "#df_sents = df_sents[['glide_id','source_level_country','authoring_org','para_id','idx_para','idx_sent','source_original_text','spacy_sent_no_paren','reported_date']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8abfa-a3f8-4acd-ba48-3b73d336dad4",
   "metadata": {},
   "source": [
    "## Data Structure Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c44777-c8cf-43f6-b74b-9221c887a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_indicators\n",
    "indicators = {\n",
    "    'i_people' : ['people','person','child','man','woman','civilian','colleague','fatality','individual']\n",
    "    ,'i_killed' : ['dead','fatal','die','kill','deceased','fatality','fatality','death','deaths'] #think about how to incorporate 2 co-existing terms \"648 people who lost their lives\"\n",
    "    ,'i_injured' : ['injure','wound','wounded','injured']\n",
    "    ,'i_damage' : ['damage','destroy','collapse','damaged']\n",
    "    ,'i_infrastructure' : ['hospital','school','university','dam','bridge','road','highway']\n",
    "    ,'i_cva' : ['xx']\n",
    "    ,'i_wash' : ['sanitation','water','sewer','drain','drainage']\n",
    "    ,'i_shelter' : ['shelter','tent','camp','blanket']\n",
    "    ,'i_food' : ['food','cook','stove','feed','feed','nutrient','meal']\n",
    "    ,'i_logistic' : ['logistic','logistics','road']\n",
    "    ,'i_health' : ['health','medical','medicine','surgery']\n",
    "    ,'i_gender_pss' : ['dignity','gender','pregnant','lactate','lactating']\n",
    "    ,'i_protection' : ['trauma','mental','disable','disability']\n",
    "    #,'i_response_capacity' : ['personnel']\n",
    "    ,'i_response' : ['personnel']\n",
    "    ,'i_other_infrastructure' : ['communicate','radio','internet','telecommunication','electric','line']\n",
    "    ,'i_money' : ['grant','loan','finance','appeal','chf','fund']\n",
    "    ,'i_other' : ['biometric']\n",
    "    ,'i_problem' : ['challenge','gap','need_to']\n",
    "    ,'i_demand_side' : ['need','demand','gap','priority', 'receive','shortage'] # note receive implies both supply and demand\n",
    "    ,'i_supply_side' : ['response','contribute','provide','source','address','deploy','receive'] # note receive implies both supply and demand\n",
    "    ,'i_tense_future' : ['xx'] #will populate this from future-tense indicator function\n",
    "\n",
    "    ,'i_assessments' : ['assess','assessment']\n",
    "}\n",
    "file = \"D://projects//_external_files//surveyor//word_indicators.xlsx\"\n",
    "\n",
    "def augment_indicators(indicators, file):\n",
    "    df = pd.read_excel(file)\n",
    "    for c in df.columns:\n",
    "        if c[0:2] == 'i_':\n",
    "            w_list = df['word'][df[c] == 1].tolist()\n",
    "            try:\n",
    "                indicators[c].extend(w_list)\n",
    "            except:\n",
    "                indicators[c] = w_list\n",
    "\n",
    "    return indicators\n",
    "\n",
    "indicators = augment_indicators(indicators, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bd81d-6211-4cf1-bf4d-7102b10385ec",
   "metadata": {},
   "source": [
    "## Data Structure Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b55d48-e7ac-4b3a-985e-697815d88da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gpe_entities(doc, adm_lvl='0'):\n",
    "    #values for adm_lvl = 0,1,2,3,\n",
    "    # -1 = self, -99 = chain\n",
    "    entities = []\n",
    "    admins = []\n",
    "    #COD_GPE\n",
    "    ents = list(extract.entities(doc))\n",
    "    if len(ents) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        for e in ents:\n",
    "            if e.label_ == 'COD_GPE':\n",
    "                entities.append(e)\n",
    "\n",
    "        # -1 means return the actual gpes\n",
    "        if adm_lvl == -1:\n",
    "            return entities\n",
    "\n",
    "        for e in entities:\n",
    "            pcode = get_pcode_from_location(e.text)\n",
    "            if (pcode is not None):\n",
    "                if (len(pcode) != 0):\n",
    "                    #if the desired level is lower than the actual reference\n",
    "                    #ignore\n",
    "                    try:\n",
    "                        if adm_lvl == -99:\n",
    "                            admins.append(get_admin_chain(pcode))\n",
    "                        else:\n",
    "                            admins.append(get_admin_chain(pcode)[adm_lvl])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    if adm_lvl != -99:\n",
    "        admins = list(set(admins))\n",
    "    if len(admins) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        #changing to return the full list, then can explode later\n",
    "        return admins #[0] \n",
    "\n",
    "df_sents['identified_gpes'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=-1))\n",
    "df_sents['identified_country'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=0))\n",
    "df_sents['identified_adm_01'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=1))\n",
    "df_sents['identified_adm_02'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=2))\n",
    "df_sents['identified_adm_chain'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_gpe_entities(x, adm_lvl=-99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee304255-1b77-47cb-a0d6-301d6d0afde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_add_indicator(df, indicators):\n",
    "    ind_counter = []\n",
    "    for ind in indicators:\n",
    "  \n",
    "        df[ind] = df['lower_lemmas'].apply(lambda x: 1 if len([w for w in x if w in indicators[ind]])>0 else 0)\n",
    "        ind_counter.append(ind)\n",
    "        #print(ind_counter)\n",
    "    df['i_count'] = df[ind_counter].sum(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f448d04-ae18-4daa-9dc0-746f63197f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['lower_lemmas'] = df_sents['spacy_sent_no_paren'].apply(lambda x: [w.lemma_.lower() for w in x])\n",
    "df_sents = find_and_add_indicator(df_sents, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3ccc1db-1817-4982-a232-15eecf17170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_excel(\"c://temp//training.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13380a08-f950-448b-9707-8663b1b6145b",
   "metadata": {},
   "source": [
    "## Layer on additional interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64fb1aa8-21b3-44c4-9185-dd3159516f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EQ-2023-000015-TUR'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sents.glide_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3a9e70-391c-4241-9845-6349e4704949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_tense_verb(doc):\n",
    "    def is_future_tense(token):\n",
    "        #Check if a token is indicative of future tense.\n",
    "        return (\n",
    "            token.tag_ == \"MD\" and token.text.lower() == \"will\"\n",
    "            or (token.dep_ == \"aux\" and token.head.lemma_ == \"will\")\n",
    "            or (token.pos_ == 'VERB' and token.head.text == \"going\" and  \"Inf\" in token.morph.get(\"VerbForm\"))\n",
    "        )\n",
    "\n",
    "    for t in doc:\n",
    "        if is_future_tense(t):\n",
    "            return f\"{t.text} {t.head}\"\n",
    "\n",
    "    \n",
    "\n",
    "def declare_primary_record_type(row):\n",
    "\n",
    "    if row['i_count'] == 0:\n",
    "        return 'background'\n",
    "    elif row['i_supply_side']:\n",
    "        return 'response_details'\n",
    "    elif row['i_demand_side']:\n",
    "        return 'demand_side'\n",
    "    elif row[['i_damage','i_health_infrastructure','i_education_infrastructure']].sum() > 0:\n",
    "        return 'damage_to_homes_and_infrastructure'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "df_sents['svot'] = df_sents['spacy_sent_no_paren'].apply(lambda doc: list(extract.subject_verb_object_triples(doc)))\n",
    "df_sents['future_verbs'] = df_sents['spacy_sent_no_paren'].apply(get_future_tense_verb)\n",
    "df_sents['i_tense_future'] = df_sents['future_verbs'].apply(lambda x: 1 if x is not None else 0)\n",
    "#df_sents['collected_indicators'] = df_sents.apply(get_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abac03e1-94b6-41ed-b6e2-ba14c778eadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_type</th>\n",
       "      <th>source_url</th>\n",
       "      <th>glide_id</th>\n",
       "      <th>idx_para</th>\n",
       "      <th>source_level_country</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_desc</th>\n",
       "      <th>source_original_text</th>\n",
       "      <th>reference_url</th>\n",
       "      <th>text</th>\n",
       "      <th>authoring_org</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>para_id</th>\n",
       "      <th>non_parenthetical_text</th>\n",
       "      <th>spacy_para_no_paren</th>\n",
       "      <th>spacy_sent_no_paren</th>\n",
       "      <th>idx_sent</th>\n",
       "      <th>identified_gpes</th>\n",
       "      <th>identified_country</th>\n",
       "      <th>identified_adm_01</th>\n",
       "      <th>identified_adm_02</th>\n",
       "      <th>identified_adm_chain</th>\n",
       "      <th>lower_lemmas</th>\n",
       "      <th>i_people</th>\n",
       "      <th>i_killed</th>\n",
       "      <th>i_injured</th>\n",
       "      <th>i_damage</th>\n",
       "      <th>i_infrastructure</th>\n",
       "      <th>i_cva</th>\n",
       "      <th>i_wash</th>\n",
       "      <th>i_shelter</th>\n",
       "      <th>i_food</th>\n",
       "      <th>i_logistic</th>\n",
       "      <th>i_health</th>\n",
       "      <th>i_gender_pss</th>\n",
       "      <th>i_protection</th>\n",
       "      <th>i_response</th>\n",
       "      <th>i_other_infrastructure</th>\n",
       "      <th>i_money</th>\n",
       "      <th>i_other</th>\n",
       "      <th>i_problem</th>\n",
       "      <th>i_demand_side</th>\n",
       "      <th>i_supply_side</th>\n",
       "      <th>i_tense_future</th>\n",
       "      <th>i_assessments</th>\n",
       "      <th>i_commodity_market</th>\n",
       "      <th>i_displacement</th>\n",
       "      <th>i_authority</th>\n",
       "      <th>i_statement_certainty</th>\n",
       "      <th>i_severity</th>\n",
       "      <th>i_change_increase</th>\n",
       "      <th>i_change_decrease</th>\n",
       "      <th>i_change_steady</th>\n",
       "      <th>i_geography</th>\n",
       "      <th>i_violence</th>\n",
       "      <th>i_count</th>\n",
       "      <th>svot</th>\n",
       "      <th>future_verbs</th>\n",
       "      <th>collected_indicators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/3937778</td>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>6</td>\n",
       "      <td>Syria</td>\n",
       "      <td>Syrian Arab Republic: Earthquakes Situation Re...</td>\n",
       "      <td>contributions; coordination; education; food a...</td>\n",
       "      <td>The situation in the affected areas remains di...</td>\n",
       "      <td>https://reliefweb.int/attachments/d075d00c-6d8...</td>\n",
       "      <td>The situation in the affected areas remains di...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>rwsitrep_https://reliefweb.int/attachments/d07...</td>\n",
       "      <td>The situation in the affected areas remains di...</td>\n",
       "      <td>(The, situation, in, the, affected, areas, rem...</td>\n",
       "      <td>(Partners, continue, to, scale, up, the, respo...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[partner, continue, to, scale, up, the, respon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[([Partners], [continue], [to, scale, up, the,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[i_response, i_supply_side, i_authority, i_sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/3934180</td>\n",
       "      <td>EQ-2023-000015-TUR</td>\n",
       "      <td>1</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>Türkiye/Syria Earthquake - Situation update #1...</td>\n",
       "      <td>logistics and telecommunications</td>\n",
       "      <td>A 7.8 magnitude earthquake hit Türkiye and Syr...</td>\n",
       "      <td>https://reliefweb.int/attachments/de9be69a-35e...</td>\n",
       "      <td>A 7.8 magnitude earthquake hit Türkiye and Syr...</td>\n",
       "      <td>Logistics Cluster</td>\n",
       "      <td>2023-02-10</td>\n",
       "      <td>rwsitrep_https://reliefweb.int/attachments/de9...</td>\n",
       "      <td>A 7.8 magnitude earthquake hit Türkiye and Syr...</td>\n",
       "      <td>(A, 7.8, magnitude, earthquake, hit, Türkiye, ...</td>\n",
       "      <td>(Aftershocks, followed, the, earthquake, and, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[aftershock, follow, the, earthquake, and, a, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[([Aftershocks], [followed], [earthquake]), ([...</td>\n",
       "      <td>None</td>\n",
       "      <td>[i_damage, i_geography]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           record_type                                    source_url  \\\n",
       "4798  situation report  https://api.reliefweb.int/v1/reports/3937778   \n",
       "4977  situation report  https://api.reliefweb.int/v1/reports/3934180   \n",
       "\n",
       "                glide_id  idx_para source_level_country  \\\n",
       "4798  EQ-2023-000015-TUR         6                Syria   \n",
       "4977  EQ-2023-000015-TUR         1              Türkiye   \n",
       "\n",
       "                                           source_title  \\\n",
       "4798  Syrian Arab Republic: Earthquakes Situation Re...   \n",
       "4977  Türkiye/Syria Earthquake - Situation update #1...   \n",
       "\n",
       "                                            source_desc  \\\n",
       "4798  contributions; coordination; education; food a...   \n",
       "4977                   logistics and telecommunications   \n",
       "\n",
       "                                   source_original_text  \\\n",
       "4798  The situation in the affected areas remains di...   \n",
       "4977  A 7.8 magnitude earthquake hit Türkiye and Syr...   \n",
       "\n",
       "                                          reference_url  \\\n",
       "4798  https://reliefweb.int/attachments/d075d00c-6d8...   \n",
       "4977  https://reliefweb.int/attachments/de9be69a-35e...   \n",
       "\n",
       "                                                   text      authoring_org  \\\n",
       "4798  The situation in the affected areas remains di...               OCHA   \n",
       "4977  A 7.8 magnitude earthquake hit Türkiye and Syr...  Logistics Cluster   \n",
       "\n",
       "     reported_date                                            para_id  \\\n",
       "4798    2023-02-26  rwsitrep_https://reliefweb.int/attachments/d07...   \n",
       "4977    2023-02-10  rwsitrep_https://reliefweb.int/attachments/de9...   \n",
       "\n",
       "                                 non_parenthetical_text  \\\n",
       "4798  The situation in the affected areas remains di...   \n",
       "4977  A 7.8 magnitude earthquake hit Türkiye and Syr...   \n",
       "\n",
       "                                    spacy_para_no_paren  \\\n",
       "4798  (The, situation, in, the, affected, areas, rem...   \n",
       "4977  (A, 7.8, magnitude, earthquake, hit, Türkiye, ...   \n",
       "\n",
       "                                    spacy_sent_no_paren  idx_sent  \\\n",
       "4798  (Partners, continue, to, scale, up, the, respo...         1   \n",
       "4977  (Aftershocks, followed, the, earthquake, and, ...         1   \n",
       "\n",
       "     identified_gpes identified_country identified_adm_01 identified_adm_02  \\\n",
       "4798            None               None              None              None   \n",
       "4977              []               None              None              None   \n",
       "\n",
       "     identified_adm_chain                                       lower_lemmas  \\\n",
       "4798                 None  [partner, continue, to, scale, up, the, respon...   \n",
       "4977                 None  [aftershock, follow, the, earthquake, and, a, ...   \n",
       "\n",
       "      i_people  i_killed  i_injured  i_damage  i_infrastructure  i_cva  \\\n",
       "4798         0         0          0         0                 0      0   \n",
       "4977         0         0          0         1                 0      0   \n",
       "\n",
       "      i_wash  i_shelter  i_food  i_logistic  i_health  i_gender_pss  \\\n",
       "4798       0          0       0           0         0             0   \n",
       "4977       0          0       0           0         0             0   \n",
       "\n",
       "      i_protection  i_response  i_other_infrastructure  i_money  i_other  \\\n",
       "4798             0           1                       0        0        0   \n",
       "4977             0           0                       0        0        0   \n",
       "\n",
       "      i_problem  i_demand_side  i_supply_side  i_tense_future  i_assessments  \\\n",
       "4798          0              0              1               0              0   \n",
       "4977          0              0              0               0              0   \n",
       "\n",
       "      i_commodity_market  i_displacement  i_authority  i_statement_certainty  \\\n",
       "4798                   0               0            1                      0   \n",
       "4977                   0               0            0                      0   \n",
       "\n",
       "      i_severity  i_change_increase  i_change_decrease  i_change_steady  \\\n",
       "4798           1                  0                  0                0   \n",
       "4977           0                  0                  0                0   \n",
       "\n",
       "      i_geography  i_violence  i_count  \\\n",
       "4798            0           0        4   \n",
       "4977            1           0        2   \n",
       "\n",
       "                                                   svot future_verbs  \\\n",
       "4798  [([Partners], [continue], [to, scale, up, the,...         None   \n",
       "4977  [([Aftershocks], [followed], [earthquake]), ([...         None   \n",
       "\n",
       "                                   collected_indicators  \n",
       "4798  [i_response, i_supply_side, i_authority, i_sev...  \n",
       "4977                            [i_damage, i_geography]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### group all the expressed indicators\n",
    "def get_indicator_columns(df):\n",
    "    inds=[]\n",
    "    for c in df.columns:\n",
    "        if c[0:2] == 'i_':\n",
    "            inds.append(c)\n",
    "\n",
    "    return inds\n",
    "\n",
    "indicator_columns = get_indicator_columns(df_sents)\n",
    "\n",
    "def find_matching_columns(row):\n",
    "    return row.index[row.eq(1)].tolist()\n",
    "\n",
    "# Create a new column containing lists of matching column names for each row\n",
    "df_sents['collected_indicators'] = df_sents[indicator_columns].apply(find_matching_columns, axis=1)\n",
    "df_sents.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c4de3-1f8c-4b1f-bcba-cb103d1e7a6f",
   "metadata": {},
   "source": [
    "## Now do analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d41478c-1800-4ab7-a8fb-a2572645cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i_people': ['people',\n",
       "  'person',\n",
       "  'child',\n",
       "  'man',\n",
       "  'woman',\n",
       "  'civilian',\n",
       "  'colleague',\n",
       "  'fatality',\n",
       "  'individual',\n",
       "  'internally',\n",
       "  'internally_displace',\n",
       "  'displace',\n",
       "  'person',\n",
       "  'displace_person',\n",
       "  'displace_people',\n",
       "  'people',\n",
       "  'people_affect',\n",
       "  'number_people',\n",
       "  'displace_people',\n",
       "  'people_need',\n",
       "  'affect_people',\n",
       "  'displacement',\n",
       "  'child',\n",
       "  'woman',\n",
       "  'woman_child',\n",
       "  'include_child',\n",
       "  'child_woman',\n",
       "  'child_protection',\n",
       "  'unaccompanied',\n",
       "  'people_receive',\n",
       "  'injure',\n",
       "  'kill_injure',\n",
       "  'settler',\n",
       "  'people_injure',\n",
       "  'die',\n",
       "  'idp',\n",
       "  'idp_site',\n",
       "  'host',\n",
       "  'idp_shelter',\n",
       "  'return',\n",
       "  'idp_camp',\n",
       "  'total',\n",
       "  'total_number',\n",
       "  'total_people',\n",
       "  'total_case',\n",
       "  'community',\n",
       "  'host_community',\n",
       "  'affect_community',\n",
       "  'member',\n",
       "  'refugee_host',\n",
       "  'refugee',\n",
       "  'asylum',\n",
       "  'seeker',\n",
       "  'asylum_seeker',\n",
       "  'refugee_camp',\n",
       "  'migrant',\n",
       "  'person',\n",
       "  'family_person',\n",
       "  'person_affect',\n",
       "  'total_family',\n",
       "  'family',\n",
       "  'patient',\n",
       "  'evacuate',\n",
       "  'protection',\n",
       "  'social',\n",
       "  'social_protection',\n",
       "  'protection_risk',\n",
       "  'protection_service',\n",
       "  'population',\n",
       "  'affected_population',\n",
       "  'movement',\n",
       "  'displace_population',\n",
       "  'affect_population',\n",
       "  'vulnerable',\n",
       "  'vulnerable_population',\n",
       "  'civilian_casualty',\n",
       "  'displace',\n",
       "  'people_displace',\n",
       "  'newly_displace',\n",
       "  'individual',\n",
       "  'child_displace',\n",
       "  'camp',\n",
       "  'live',\n",
       "  'people_live',\n",
       "  'gbv',\n",
       "  'support',\n",
       "  'psychosocial',\n",
       "  'psychosocial_support',\n",
       "  'support_people',\n",
       "  'reach_people',\n",
       "  'wfp_reach',\n",
       "  'people_reach',\n",
       "  'number_people',\n",
       "  'child_kill'],\n",
       " 'i_killed': ['dead',\n",
       "  'fatal',\n",
       "  'die',\n",
       "  'kill',\n",
       "  'deceased',\n",
       "  'fatality',\n",
       "  'fatality',\n",
       "  'death',\n",
       "  'deaths'],\n",
       " 'i_injured': ['injure', 'wound', 'wounded', 'injured'],\n",
       " 'i_damage': ['damage', 'destroy', 'collapse', 'damaged'],\n",
       " 'i_infrastructure': ['hospital',\n",
       "  'school',\n",
       "  'university',\n",
       "  'dam',\n",
       "  'bridge',\n",
       "  'road',\n",
       "  'highway'],\n",
       " 'i_cva': ['xx'],\n",
       " 'i_wash': ['sanitation',\n",
       "  'water',\n",
       "  'sewer',\n",
       "  'drain',\n",
       "  'drainage',\n",
       "  'hygiene',\n",
       "  'wash',\n",
       "  'sanitation',\n",
       "  'water_sanitation',\n",
       "  'drinking',\n",
       "  'drinking_water',\n",
       "  'water_source'],\n",
       " 'i_shelter': ['shelter', 'tent', 'camp', 'blanket'],\n",
       " 'i_food': ['food',\n",
       "  'cook',\n",
       "  'stove',\n",
       "  'feed',\n",
       "  'feed',\n",
       "  'nutrient',\n",
       "  'meal',\n",
       "  'malnutrition',\n",
       "  'acute',\n",
       "  'acute_malnutrition',\n",
       "  'maize',\n",
       "  'rice',\n",
       "  'bean',\n",
       "  'produce',\n",
       "  'food_insecurity',\n",
       "  'acute_food',\n",
       "  'food',\n",
       "  'wheat',\n",
       "  'flour',\n",
       "  'wheat_flour',\n",
       "  'milk',\n",
       "  'school_feeding',\n",
       "  'food_security',\n",
       "  'food_assistance',\n",
       "  'nutrition',\n",
       "  'staple',\n",
       "  'staple_food',\n",
       "  'provision',\n",
       "  'provide_food',\n",
       "  'hot_meal',\n",
       "  'food_price'],\n",
       " 'i_logistic': ['logistic',\n",
       "  'logistics',\n",
       "  'road',\n",
       "  'border',\n",
       "  'truck',\n",
       "  'load',\n",
       "  'distribution',\n",
       "  'fuel',\n",
       "  'electricity',\n",
       "  'facility',\n",
       "  'health_facility',\n",
       "  'humanitarian_access',\n",
       "  'road',\n",
       "  'infrastructure',\n",
       "  'trucking',\n",
       "  'logistics',\n",
       "  'logistics_cluster',\n",
       "  'storage',\n",
       "  'cargo',\n",
       "  'supply',\n",
       "  'deliver',\n",
       "  'base',\n",
       "  'warehouse',\n",
       "  'mobile',\n",
       "  'logistic',\n",
       "  'instal',\n",
       "  'roadway',\n",
       "  'bridge',\n",
       "  'highway',\n",
       "  'railway',\n",
       "  'airport',\n",
       "  'port',\n",
       "  'dam',\n",
       "  'tunnel',\n",
       "  'pipeline',\n",
       "  'water treatment plant',\n",
       "  'power plant',\n",
       "  'telecommunications network',\n",
       "  'sewer system',\n",
       "  'public transportation',\n",
       "  'grid',\n",
       "  'network',\n",
       "  'reservoir'],\n",
       " 'i_health': ['health',\n",
       "  'medical',\n",
       "  'medicine',\n",
       "  'surgery',\n",
       "  'acute',\n",
       "  'acute_malnutrition',\n",
       "  'treatment',\n",
       "  'case',\n",
       "  'case_report',\n",
       "  'suspect',\n",
       "  'suspect_case',\n",
       "  'cholera_case',\n",
       "  'report_case',\n",
       "  'case_death',\n",
       "  'cholera',\n",
       "  'new_case',\n",
       "  'coronavirus',\n",
       "  'health',\n",
       "  'ministry_health',\n",
       "  'care',\n",
       "  'health_care',\n",
       "  'mental_health',\n",
       "  'confirm_case',\n",
       "  'case_confirm',\n",
       "  'supply',\n",
       "  'kit',\n",
       "  'medical',\n",
       "  'medical_supply',\n",
       "  'medicine',\n",
       "  'health_facility',\n",
       "  'hospital',\n",
       "  'admit',\n",
       "  'operate',\n",
       "  'health_service',\n",
       "  'healthcare',\n",
       "  'outbreak',\n",
       "  'cholera_outbreak',\n",
       "  'disease',\n",
       "  'disease_outbreak',\n",
       "  'spread',\n",
       "  'number_case'],\n",
       " 'i_gender_pss': ['dignity',\n",
       "  'gender',\n",
       "  'pregnant',\n",
       "  'lactate',\n",
       "  'lactating',\n",
       "  'child',\n",
       "  'woman',\n",
       "  'woman_child',\n",
       "  'include_child',\n",
       "  'child_woman',\n",
       "  'child_protection',\n",
       "  'unaccompanied',\n",
       "  'mental_health',\n",
       "  'mental',\n",
       "  'protection',\n",
       "  'social',\n",
       "  'social_protection',\n",
       "  'protection_risk',\n",
       "  'protection_service',\n",
       "  'vulnerable',\n",
       "  'vulnerable_population',\n",
       "  'child_displace',\n",
       "  'gbv',\n",
       "  'psychosocial',\n",
       "  'psychosocial_support',\n",
       "  'child_kill'],\n",
       " 'i_protection': ['trauma', 'mental', 'disable', 'disability'],\n",
       " 'i_response': ['personnel',\n",
       "  'funding',\n",
       "  'unicef',\n",
       "  'require',\n",
       "  'appeal',\n",
       "  'fund',\n",
       "  'gap',\n",
       "  'requirement',\n",
       "  'funding_gap',\n",
       "  'response',\n",
       "  'plan',\n",
       "  'response_plan',\n",
       "  'humanitarian_response',\n",
       "  'emergency_response',\n",
       "  'humanitarian',\n",
       "  'humanitarian_assistance',\n",
       "  'humanitarian_need',\n",
       "  'need_humanitarian',\n",
       "  'actor',\n",
       "  'wfp',\n",
       "  'lead',\n",
       "  'coordination',\n",
       "  'local',\n",
       "  'united',\n",
       "  'nations',\n",
       "  'united_nations',\n",
       "  'humanitarian_community',\n",
       "  'assessment',\n",
       "  'conduct',\n",
       "  'rapid',\n",
       "  'team',\n",
       "  'need_assessment',\n",
       "  'rapid_assessment',\n",
       "  'wfp_continue',\n",
       "  'continue_support',\n",
       "  'partner_continue',\n",
       "  'continue_increase',\n",
       "  'deliver',\n",
       "  'address',\n",
       "  'immediate',\n",
       "  'emergency',\n",
       "  'management',\n",
       "  'emergency_management',\n",
       "  'emergency_shelter',\n",
       "  'humanitarian_access',\n",
       "  'disaster_management',\n",
       "  'operation',\n",
       "  'rescue',\n",
       "  'search',\n",
       "  'search_rescue',\n",
       "  'assistance',\n",
       "  'cash_assistance',\n",
       "  'assistance_people',\n",
       "  'provide',\n",
       "  'provide_food',\n",
       "  'hot_meal',\n",
       "  'support',\n",
       "  'psychosocial',\n",
       "  'psychosocial_support',\n",
       "  'support_people',\n",
       "  'wfp_support',\n",
       "  'reach',\n",
       "  'reach_people',\n",
       "  'wfp_reach',\n",
       "  'people_reach'],\n",
       " 'i_other_infrastructure': ['communicate',\n",
       "  'radio',\n",
       "  'internet',\n",
       "  'telecommunication',\n",
       "  'electric',\n",
       "  'line'],\n",
       " 'i_money': ['grant', 'loan', 'finance', 'appeal', 'chf', 'fund'],\n",
       " 'i_other': ['biometric'],\n",
       " 'i_problem': ['challenge', 'gap', 'need_to'],\n",
       " 'i_demand_side': ['need', 'demand', 'gap', 'priority', 'receive', 'shortage'],\n",
       " 'i_supply_side': ['response',\n",
       "  'contribute',\n",
       "  'provide',\n",
       "  'source',\n",
       "  'address',\n",
       "  'deploy',\n",
       "  'receive'],\n",
       " 'i_tense_future': ['xx'],\n",
       " 'i_assessments': ['assess', 'assessment'],\n",
       " 'i_commodity_market': ['commodity',\n",
       "  'market',\n",
       "  'trade',\n",
       "  'wheat',\n",
       "  'flour',\n",
       "  'wheat_flour',\n",
       "  'average_price',\n",
       "  'milk',\n",
       "  'consumption',\n",
       "  'cash',\n",
       "  'income',\n",
       "  'inflation',\n",
       "  'staple',\n",
       "  'staple_food',\n",
       "  'assistance',\n",
       "  'cash_assistance',\n",
       "  'assistance_people',\n",
       "  'price_increase',\n",
       "  'demand',\n",
       "  'price',\n",
       "  'trend',\n",
       "  'food_price',\n",
       "  'trend_average',\n",
       "  'trend_price',\n",
       "  'region_price'],\n",
       " 'i_displacement': ['internally_displace',\n",
       "  'displace',\n",
       "  'displace_person',\n",
       "  'displace_people',\n",
       "  'displace_people',\n",
       "  'displacement',\n",
       "  'unaccompanied',\n",
       "  'idp',\n",
       "  'idp_site',\n",
       "  'idp_shelter',\n",
       "  'idp_camp',\n",
       "  'host_community',\n",
       "  'refugee_host',\n",
       "  'refugee',\n",
       "  'asylum',\n",
       "  'seeker',\n",
       "  'asylum_seeker',\n",
       "  'refugee_camp',\n",
       "  'migrant',\n",
       "  'evacuate',\n",
       "  'displace',\n",
       "  'people_displace',\n",
       "  'newly_displace',\n",
       "  'child_displace',\n",
       "  'camp'],\n",
       " 'i_authority': ['governorate',\n",
       "  'un',\n",
       "  'agency',\n",
       "  'un_agency',\n",
       "  'state',\n",
       "  'declare',\n",
       "  'state_emergency',\n",
       "  'ministry',\n",
       "  'ministry_health',\n",
       "  'unrwa',\n",
       "  'accord',\n",
       "  'accord_ministry',\n",
       "  'official',\n",
       "  'partner',\n",
       "  'cluster',\n",
       "  'humanitarian_partner',\n",
       "  'unhcr',\n",
       "  'unhcr_partner',\n",
       "  'cluster_partner',\n",
       "  'partner_reach',\n",
       "  'government',\n",
       "  'united',\n",
       "  'nations',\n",
       "  'united_nations',\n",
       "  'department',\n",
       "  'ocha',\n",
       "  'national',\n",
       "  'authority',\n",
       "  'foreign',\n",
       "  'foreign_national',\n",
       "  'provide'],\n",
       " 'i_statement_certainty': ['estimate',\n",
       "  'estimate_people',\n",
       "  'estimate',\n",
       "  'reportedly'],\n",
       " 'i_severity': ['severe',\n",
       "  'severe_acute',\n",
       "  'moderate_acute',\n",
       "  'moderate',\n",
       "  'dire',\n",
       "  'priority',\n",
       "  'important',\n",
       "  'scale',\n",
       "  'total',\n",
       "  'total_number',\n",
       "  'total_people',\n",
       "  'total_case',\n",
       "  'heavy',\n",
       "  'impact',\n",
       "  'significant',\n",
       "  'devastating',\n",
       "  'effect',\n",
       "  'need',\n",
       "  'meet',\n",
       "  'urgent',\n",
       "  'urgent_need',\n",
       "  'address',\n",
       "  'immediate',\n",
       "  'emergency',\n",
       "  'light',\n",
       "  'light_moderate',\n",
       "  'partially',\n",
       "  'completely',\n",
       "  'partially_destroy',\n",
       "  'high',\n",
       "  'high_risk',\n",
       "  'high_number',\n",
       "  'rate',\n",
       "  'high_level',\n",
       "  'intensity',\n",
       "  'severely_affect'],\n",
       " 'i_change_increase': ['deteriorate',\n",
       "  'increase_compare',\n",
       "  'newly_displace',\n",
       "  'newly',\n",
       "  'rise',\n",
       "  'increase_number',\n",
       "  'increase',\n",
       "  'increase_risk',\n",
       "  'price_increase',\n",
       "  'increasingly'],\n",
       " 'i_change_decrease': ['decrease', 'decrease_compare', 'compare_average'],\n",
       " 'i_change_steady': ['situation_remain',\n",
       "  'remain',\n",
       "  'remain_high',\n",
       "  'people_remain',\n",
       "  'stable',\n",
       "  'remain_stable',\n",
       "  'maintain',\n",
       "  'maintain_strength'],\n",
       " 'i_geography': ['border',\n",
       "  'crossing',\n",
       "  'cross',\n",
       "  'point',\n",
       "  'border_crossing',\n",
       "  'cross_border',\n",
       "  'crossing_point',\n",
       "  'village',\n",
       "  'villager',\n",
       "  'village_tract',\n",
       "  'tract',\n",
       "  'location',\n",
       "  'regional',\n",
       "  'urban',\n",
       "  'rural',\n",
       "  'rural_area',\n",
       "  'urban_area',\n",
       "  'south',\n",
       "  'north',\n",
       "  'west',\n",
       "  'north_south',\n",
       "  'east',\n",
       "  'northern',\n",
       "  'eastern',\n",
       "  'northern_portion',\n",
       "  'city',\n",
       "  'district',\n",
       "  'district_region',\n",
       "  'township',\n",
       "  'national',\n",
       "  'region',\n",
       "  'region_country',\n",
       "  'western',\n",
       "  'country',\n",
       "  'neighbouring_country',\n",
       "  'neighbouring',\n",
       "  'neighboring_country',\n",
       "  'neighboring'],\n",
       " 'i_violence': ['armed',\n",
       "  'conflict',\n",
       "  'armed_group',\n",
       "  'armed_conflict',\n",
       "  'forces',\n",
       "  'clash',\n",
       "  'security',\n",
       "  'ammunition',\n",
       "  'live_ammunition',\n",
       "  'unrest',\n",
       "  'force',\n",
       "  'attack',\n",
       "  'civilian',\n",
       "  'violence',\n",
       "  'civilian_casualty',\n",
       "  'shooting',\n",
       "  'firearm']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20cbaca3-cbdc-4320-92de-158a890db7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sents[['spacy_sent_no_paren','future_verbs','collected_indicators']][(df_sents['future_verbs'].isna() == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6308b-69b7-45ab-bddb-a1bea4ea4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents[['spacy_sent_no_paren','future_verbs','collected_indicators']][(df_sents['i_displacement'] == 1) & (df_sents['future_verbs'].isna() == False)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc2aa56-24ad-432b-98fe-5c2c17f02753",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = 'i_displacement'\n",
    "\n",
    "#df_sents[['reported_date','source_original_text','spacy_sent_no_paren','collected_indicators']][(df_sents[indicator] == 1) & (df_sents['future_verbs'].isna() == False)].sort_values(by='reported_date').to_excel(f\"c://temp//{indicator}_future.xlsx\")\n",
    "#df_sents[['reported_date','source_original_text','spacy_sent_no_paren','collected_indicators']][(df_sents[indicator] == 1)]\n",
    "df_sents.to_excel(\"c://temp//all.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "135ccff3-394c-4ce8-8be3-b7ff9df474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicators(df):\n",
    "    inds=[]\n",
    "    for c in df.columns:\n",
    "        if c[0:2] == 'i_':\n",
    "            if df[c].tolist()[0] == 1:\n",
    "                inds.append(c)\n",
    "\n",
    "    return inds\n",
    "\n",
    "def get_verb_tense_indicator(doc):\n",
    "    for token in doc:\n",
    "        print(f\"{token.lemma_} -- {token.pos_} -- {token.morph}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa5083-fbb6-445a-88dc-3ff19d2c674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "df_focus = df_sents.sample(10)\n",
    "\n",
    "for index, row in df_focus[['spacy_sent_no_paren','collected_indicators']].iterrows():\n",
    "    print(row[0])\n",
    "    print(row[1])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c5864-4bf9-4ffa-a732-cffce935f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['i_gender_pss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c02d9-d878-41e5-8235-d445ef1d6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_focus  = df_sents.sample(1)\n",
    "\n",
    "s = df_focus['spacy_sent_no_paren'].tolist()[0]\n",
    "idx = df_focus['spacy_sent_no_paren'].index\n",
    "print(idx)\n",
    "print()\n",
    "print(re.sub(\"\\n\", \" \", s.text))\n",
    "print(get_indicators(df_focus))\n",
    "print()\n",
    "\n",
    "#get_verb_tense_indicator(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e21bd-1a36-42ce-acb2-0b2139b108a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causal factors\n",
    "\n",
    "\"due to\" -- \"ADP ADP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a575b37a-57c5-4ce1-82a0-1d13230d4ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The greatest increases in population densities were in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mersin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COD_GPE</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Niğde\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " , and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Adana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COD_GPE</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'The greatest increases in population densities were in Mersin , Niğde , and Adana '\n",
    "doc = nlp(text)\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b547a62-a703-4fdb-aeec-88487a8a3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_date(date):\n",
    "    date_object = datetime.strptime(date, \"%d %b %Y\")\n",
    "    iso_date = date_object.date().isoformat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
