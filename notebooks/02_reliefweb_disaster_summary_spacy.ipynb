{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ec487232-ba50-42d3-9a83-af5151ea68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from textacy import extract\n",
    "\n",
    "from collections import defaultdict \n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b4ce36a7-9ecd-48f4-ada5-88df466111c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=12, tm_mday=10, tm_hour=8, tm_min=11, tm_sec=8, tm_wday=6, tm_yday=344, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(time.localtime())\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a43d860-516f-49d6-a9bf-8144b7255138",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_summary_preprocessed_file = \"D://projects//_external_files//surveyor//rw_disaster_preprocessed//disaster_summaries_preprocessed_69079bdfb35643eea3b17fe452c63d29.xlsx\"\n",
    "\n",
    "df = pd.read_excel(disaster_summary_preprocessed_file)\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0abef08c-9dbf-45f0-a3b7-d5724f6c14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "\n",
    "sentences = []\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b1def37c-68a5-42d3-86ed-0eef298de998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    #print()\n",
    "    #print(doc)\n",
    "    for sent in doc.sents:\n",
    "        #print(sent)\n",
    "        #create new doc objects for each sentence and append to a list\n",
    "        doc_from_span = spacy.tokens.Doc(doc.vocab, words=[token.text for token in sent])\n",
    "        sentences.append(doc_from_span)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def expand_to_sentence_level(doc):\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        sent_text = sent.text\n",
    "        if len(sent_text) > 20:\n",
    "            sentences.append(nlp(sent_text)) # horrendously inefficient but...\n",
    "    if len(sentences) == 0:\n",
    "        sentences.append(nlp(\"No content to return.\"))\n",
    "    return sentences\n",
    "\n",
    "# Function to increment by one for each idx_parad\n",
    "def generate_sent_id(group, new_column_name='idx_sent'):\n",
    "    group[new_column_name] = range(0, len(group))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3accd8c6-3e9e-41e7-ac23-f1c021f0a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_type', 'status', 'source_url', 'glide_id', 'idx_para',\n",
       "       'source_level_country', 'source_title', 'source_desc',\n",
       "       'source_original_text', 'reference_url', 'text', 'authoring_org',\n",
       "       'reported_date', 'references', 'reference_auth_org',\n",
       "       'reference_date_str', 'reference_date_iso', 'para_id',\n",
       "       'non_parenthetical_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "85068c8b-06cf-4e8b-8fd2-261758037193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on ongoing for nowd\n",
    "df_sents = df[df['status'] == 'ongoing'].copy()\n",
    "df_sents['spacy_para_no_paren'] = df_sents['non_parenthetical_text'].apply(lambda x: nlp(x))\n",
    "df_sents['spacy_sent_no_paren'] = df_sents['spacy_para_no_paren'].apply(expand_to_sentence_level)\n",
    "df_sents = df_sents.explode('spacy_sent_no_paren')\n",
    "\n",
    "# Apply the function to the DataFrame using groupby on 'idx_para'\n",
    "df_sents = df_sents.groupby(['para_id','idx_para']).apply(generate_sent_id).reset_index(drop=True)\n",
    "df_sents = df_sents[['glide_id','para_id','idx_para','idx_sent','source_original_text','spacy_sent_no_paren','reference_date_iso']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e5fa5-151a-476a-a608-4d1dd304636d",
   "metadata": {},
   "source": [
    "## Data Structure Completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7fe7f050-bffc-4055-9e91-2ce3a09f9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_indicators\n",
    "indicators = {\n",
    "    'i_people' : ['people','person','child','man','woman','civilian','colleague','fatality','individual']\n",
    "    ,'i_killed' : ['dead','fatal','die','kill','deceased','fatality','fatality','death','deaths'] #think about how to incorporate 2 co-existing terms \"648 people who lost their lives\"\n",
    "    ,'i_injured' : ['injure','wound','wounded','injured']\n",
    "    ,'i_damage' : ['damage','destroy','collapse']\n",
    "    ,'i_health_infrastructure' : ['hospital','surgery']\n",
    "    ,'i_education_infrastructure' : ['school','university']\n",
    "    ,'i_cash_xfer' : ['xx']\n",
    "    ,'i_wash' : ['sanitation','water','sewer','drain','drainage']\n",
    "    ,'i_shelter' : ['shelter','tent','camp','blanket']\n",
    "    ,'i_food' : ['food','cook','stove','feed','feed','nutrient','meal']\n",
    "    ,'i_health' : ['health','medical','medicine']\n",
    "    ,'i_gender_vuln' : ['dignity','gender','pregnant','lactate','lactating']\n",
    "    ,'i_protection' : ['trauma','mental']\n",
    "    ,'i_response_capacity' : ['personnel']\n",
    "    ,'i_other_infrastructure' : ['communicate','radio','internet','telecommunication','electric','line']\n",
    "    ,'i_money' : ['grant','loan','finance','appeal','chf','fund']\n",
    "    ,'i_other' : ['biometric']\n",
    "    ,'i_problem' : ['challenge']\n",
    "    ,'i_demand_side' : ['need','demand','gap','priority', 'receive'] # note receive implies both supply and demand\n",
    "    ,'i_supply_side' : ['response','contribute','provide','source','address','deploy','receive'] # note receive implies both supply and demand\n",
    "\n",
    "    ,'i_assessments' : ['assess','assessment']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8e246a87-b286-4858-80e4-8d32e612a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric_value(doc, indicator):\n",
    "    #indicator needs to be either i_killed, or i_injured\n",
    "    \n",
    "\n",
    "    key_values = []\n",
    "    just_count = []\n",
    "    \n",
    "    def check_flags(lst):\n",
    "        for l in lst:\n",
    "            if l == -1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def reset_indicators():\n",
    "        return -1, -1, -1\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        noun, attribute, count = reset_indicators()\n",
    "    \n",
    "        \n",
    "                \n",
    "        for t in sent:\n",
    "            #print(t)\n",
    "            if (t.pos_ == 'NUM') & (t.ent_type_ not in ['DATE','TIME']):\n",
    "                count = t\n",
    "    \n",
    "            if t.lemma_ in indicators[indicator]:\n",
    "                attribute = t\n",
    "            if check_flags([attribute,count]):\n",
    "    \n",
    "                noun_att_cnt = (attribute,count)\n",
    "                key_values.append(noun_att_cnt)\n",
    "                just_count.append(count)\n",
    "    \n",
    "                noun, attribute, count = reset_indicators()\n",
    "\n",
    "    #if more than 1 figure is returned, typically those will be\n",
    "    #contextualizing numbers, just return the first\n",
    "    if len(just_count) > 0:\n",
    "        #return [just_count,key_values]\n",
    "        return just_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c7f08412-eddc-4846-b82f-e1bc3dbb9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['num_killed'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_numeric_value(x, 'i_killed'))\n",
    "df_sents['num_injured'] = df_sents['spacy_sent_no_paren'].apply(lambda x: extract_numeric_value(x, 'i_injured'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4bda2294-3acf-4967-ab8f-45423523ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sents['spacy_sent_no_paren'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "949b58dc-a256-4cda-a453-5c7275273d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_csv(\"c://temp//foo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2914379-fbe9-4754-9a08-e08d0a57b17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
