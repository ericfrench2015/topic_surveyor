{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6fb2107-24f1-4355-9b1f-157915d02dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from textacy import extract\n",
    "\n",
    "from collections import defaultdict \n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62dddbe2-cc32-4ea6-90a4-e5d54c109b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=11, tm_mday=25, tm_hour=11, tm_min=20, tm_sec=55, tm_wday=5, tm_yday=329, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "dir(time)\n",
    "print(time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc9b065-6c1f-44ff-a53c-9a79e3f1a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files\n",
    "pcode_file = \"D://projects//_external_files//cod_files//combined_locations//locations.csv\"\n",
    "situation_reports = \"c://temp//100_situation_reports.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b94269-2fda-432c-bd1d-1c5097f2be43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load geolocation_services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20cfd8aa-4f25-4857-abad-ba987499fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.read_csv(pcode_file)\n",
    "\n",
    "def get_pcode_from_location(loc, country_prefix='XX', lang_code='all'):\n",
    "\n",
    "    if country_prefix != 'XX': #if the country prefix is set, limit search to that\n",
    "        df_loc = df_location[df_location['pcode_prefix'] == country_prefix]\n",
    "    else:\n",
    "        df_loc = df_location\n",
    "\n",
    "    if lang_code != 'all': #secondary filter - especially important to remove dupes with diff langs share the same script\n",
    "        df_loc = df_loc[df_loc['lang_code'] == lang_code]\n",
    "        \n",
    "    matches = df_loc['pcode'][df_loc['location_name'].str.lower() == loc.lower()].tolist()\n",
    "\n",
    "    #if the match fails, try again on the normalized name\n",
    "    if len(matches) == 0:\n",
    "        #remove common variations in names that can cause misses\n",
    "        n_loc = re.sub(r'[^a-zA-Z]', '', loc)\n",
    "\n",
    "        #this will cause problems for non-English.. so if then len is 0, exit\n",
    "        if len(n_loc) == 0:\n",
    "            return []\n",
    "            \n",
    "        matches = df_loc['pcode'][df_loc['location_normalized'].str.lower() == n_loc.lower()].tolist()\n",
    "        \n",
    "\n",
    "    #now check results\n",
    "    if len(matches) > 1:\n",
    "        #print(f\"more than 1 matches... likely due to different granularity of entities with the same name (ie. Herat City in Herat Province) {matches}\")\n",
    "        #print(f\"returning the lowest granularity match. {min(matches, key=len)}\")\n",
    "        #print(\"if the pcodes are all the same granularity.... you get the first element.\")\n",
    "        return min(matches, key=len)\n",
    "            \n",
    "        return matches\n",
    "    elif len(matches) == 1:\n",
    "        return matches\n",
    "\n",
    "    else:\n",
    "        #couldn't find a match, do a fuzzy search\n",
    "        compare_list = list(set(df_loc['location_name'].tolist()))\n",
    "        possible_matches=[]\n",
    "        for i in compare_list:\n",
    "            if fuzz.ratio(loc,i) > 70:\n",
    "                possible_matches.append(i)\n",
    "                print (f\"No exact match to '{loc}'. see if these alternative spellings are correct: {possible_matches}\")\n",
    "\n",
    "    \n",
    "    return []\n",
    "\n",
    "assert get_pcode_from_location('istanbul')[0] == 'TUR034'\n",
    "\n",
    "def get_adm_lvl_from_pcode(pcode):\n",
    "    return list(set(df_location['adm_lvl'][df_location['pcode'] == pcode].tolist()))\n",
    "    \n",
    "def get_name_in_lang(pcode, lang='en'):\n",
    "    return list(set(df_location['location_name'][(df_location['pcode'] == pcode) & (df_location['lang_code'] == lang)].tolist()))\n",
    "\n",
    "def get_descendents_of(pcode, lang='en', include_self=True):\n",
    "    if include_self==True:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)]\n",
    "    else:\n",
    "        return df_location[df_location['pcode'].str.contains(pcode) & (df_location['lang_code'] == lang)\\\n",
    "        & (df_location['pcode'] != pcode)]\n",
    "\n",
    "def get_admin_chain(pcode, lang='en'):\n",
    "    split_pcode = df_location['split_pcode'][df_location['pcode'] == pcode].tolist()[0]\n",
    "    levels = split_pcode.split(\".\")\n",
    "    pc =''\n",
    "    admin_chain = []\n",
    "    #rebuild the pcode one level at a time\n",
    "    for i in levels:\n",
    "        pc = pc + i\n",
    "        admin_chain.append(df_location['location_name'][(df_location['pcode'] == pc) & (df_location['lang_code'] == lang)].tolist()[0])\n",
    "\n",
    "    return admin_chain\n",
    "\n",
    "def get_all_locations(lang_code='all'):\n",
    "\n",
    "    #return all unique location names\n",
    "    if lang_code == 'all':\n",
    "        return list(set(df_location['location_name'].to_list()))\n",
    "    else:\n",
    "        return list(set(df_location['location_name'][df_location['lang_code'] == lang_code].to_list()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfa657-7ee5-43ee-bc0f-4c14300359a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22bbf14-2b70-4745-9a52-c78a89af3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "#ruler.add_patterns(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8734f6d-b090-454c-aad7-fda7d38d0b12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Preprocessing Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf238f1-4813-4690-9dcc-c7d9c704364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_preprocess(text):\n",
    "    \n",
    "    def convert_spelled_nums_to_digit(token):\n",
    "        mappings = {\n",
    "            'one' : 1,'two' : 2,'three' : 3,'four' : 4,'five' : 5,'six' : 6,'seven' : 7,'eight' : 8,'nine' : 9, 'ten' : 10\n",
    "            ,'eleven' : 11, 'twelve' : 12, 'thirteen':13, 'fourteen':14, 'fifteen':15, 'sixteen':16, 'seventeen':17\n",
    "            ,'eighteen':18, 'nineteen':19, 'twenty':20\n",
    "        }\n",
    "    \n",
    "        if mappings.get(token) is not None:\n",
    "            return mappings[token]\n",
    "        else:\n",
    "            return token\n",
    "        \n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = text.replace(\"-\",\"_\") #replace so tokenization doesn't separate\n",
    "\n",
    "    #turn 'four' into 4\n",
    "    text = ' '.join([str(convert_spelled_nums_to_digit(t)) for t in text.split(\" \")])\n",
    "\n",
    "\n",
    "    # remove content in parentheses\n",
    "    #processed_string = re.sub(r'\\([^)]*\\)', '', input_string)\n",
    "\n",
    "    #remove all non alpha numeric and punctuation\n",
    "    pattern = r'[^a-zA-Z0-9\\s\\,\\.\\?\\!\\-\\(\\)]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    pattern = r'(\\d+)\\s+million'\n",
    "    text = re.sub(r'(\\d+)\\s+million', r'\\1,000,000', text)\n",
    "\n",
    "    \n",
    "    #remove commas that serve as thousands separators\n",
    "    #Hack... fix this so I don't have to run it 3x\n",
    "    text = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', text)\n",
    "    text = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', text)\n",
    "    text = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', text)\n",
    "    text = text.replace(\"\\s+\",\"\\s\")\n",
    "    return text\n",
    "\n",
    "def string_remove_parenthetical_content(text):\n",
    "    # Use regular expression to remove content inside parentheses\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff189ddf-4fc4-4d75-a881-0274b2b919ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load NLP routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e49e55-1a83-4914-803f-6b5cdb069a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Create patterns and add to the entity ruler to better find locations\n",
    "\n",
    "all_locs = get_all_locations(lang_code='en')\n",
    "gpes = []\n",
    "\n",
    "STOP_LOCS = ['of','can']\n",
    "all_locs = [e for e in all_locs if e.lower() not in STOP_LOCS]\n",
    "\n",
    "# create pattern rules for locations based on the COD files\n",
    "for l in all_locs:\n",
    "    token_sequence=[]\n",
    "    for token in l.split('\\s+'):\n",
    "        token_sequence.append({\"LOWER\":token.lower()})\n",
    "    x = {'label':'GPE', 'pattern': token_sequence, 'id':get_pcode_from_location(l, lang_code='en')[0]}\n",
    "    gpes.append(x)\n",
    "    #print(get_pcode_from_location(l, lang_code='en'))\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "ruler.add_patterns(gpes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8591a05-cefd-41b9-800f-4f9ac23b7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_indicators\n",
    "indicators = {\n",
    "    'i_people' : ['people','person','child','man','woman']\n",
    "    ,'i_civilian' : ['civilian']\n",
    "    ,'i_killed' : ['dead','fatal','die','kill','deceased'] #think about how to incorporate 2 co-existing terms \"648 people who lost their lives\"\n",
    "    ,'i_injured' : ['injure','wound']\n",
    "    ,'i_damage' : ['damage','destroy','collapse']\n",
    "    ,'i_health_infrastructure' : ['hospital','surgery']\n",
    "    ,'i_education_infrastructure' : ['school','university']\n",
    "    ,'i_cash_xfer' : ['xx']\n",
    "    ,'i_wash' : ['sanitation','water','sewer','drain','drainage']\n",
    "    ,'i_shelter' : ['shelter','tent','camp','blanket']\n",
    "    ,'i_food' : ['food','cook','stove','feed','feed','nutrient','meal']\n",
    "    ,'i_health' : ['health','medical','medicine']\n",
    "    ,'i_gender_vuln' : ['dignity','gender','pregnant','lactate','lactating']\n",
    "    ,'i_protection' : ['trauma','mental']\n",
    "    ,'i_response_capacity' : ['personnel']\n",
    "    ,'i_other_infrastructure' : ['communicate','radio','internet','telecommunication','electric','line']\n",
    "    ,'i_money' : ['grant','loan','finance','appeal','chf','fund']\n",
    "    ,'i_other' : ['biometric']\n",
    "    ,'i_problem' : ['challenge']\n",
    "    ,'i_demand_side' : ['need','demand','gap','priority', 'receive'] # note receive implies both supply and demand\n",
    "    ,'i_supply_side' : ['response','contribute','provide','source','address','deploy','receive'] # note receive implies both supply and demand\n",
    "\n",
    "    ,'i_assessments' : ['assess','assessment']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f589028-1219-48ce-9e27-283ce730511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_tense_verb(doc):\n",
    "    def is_future_tense(token):\n",
    "        #Check if a token is indicative of future tense.\n",
    "        return (\n",
    "            token.tag_ == \"MD\" and token.text.lower() == \"will\"\n",
    "            or (token.dep_ == \"aux\" and token.head.lemma_ == \"will\")\n",
    "        )\n",
    "\n",
    "    for t in doc:\n",
    "        if is_future_tense(t):\n",
    "            return f\"{t.text} {t.head}\"\n",
    "\n",
    "def find_and_add_indicator(df, indicators):\n",
    "    ind_counter = []\n",
    "    for ind in indicators:\n",
    "  \n",
    "        df[ind] = df['lower_lemmas'].apply(lambda x: 1 if len([w for w in x if w in indicators[ind]])>0 else 0)\n",
    "        ind_counter.append(ind)\n",
    "        #print(ind_counter)\n",
    "    df['i_count'] = df[ind_counter].sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def declare_primary_record_type(row):\n",
    "\n",
    "    if row['i_count'] == 0:\n",
    "        return 'background'\n",
    "    elif row['i_supply_side']:\n",
    "        return 'response_details'\n",
    "    elif row['i_demand_side']:\n",
    "        return 'demand_side'\n",
    "    elif row[['i_damage','i_health_infrastructure','i_education_infrastructure']].sum() > 0:\n",
    "        return 'damage_to_homes_and_infrastructure'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obtain_killed_numeric_value(doc):\n",
    "\n",
    "    key_values = []\n",
    "    just_count = []\n",
    "    \n",
    "    def check_flags(lst):\n",
    "        for l in lst:\n",
    "            if l == -1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    #doc = doc.tolist()[0]\n",
    "    attribute = -1\n",
    "    noun = -1\n",
    "    count = -1\n",
    "\n",
    "    for t in doc:\n",
    "        if str(t).isdigit():\n",
    "            count = t\n",
    "        if t in indicators['i_people']:\n",
    "            noun = t\n",
    "        if t in indicators['i_killed']:\n",
    "            attribute = t\n",
    "\n",
    "        if check_flags([noun,attribute,count]):\n",
    "\n",
    "            noun_att_cnt = (noun,attribute,count)\n",
    "            key_values.append(noun_att_cnt)\n",
    "            just_count.append(count)\n",
    "\n",
    "            noun = -1\n",
    "            attribute = -1\n",
    "            count = -1\n",
    "\n",
    "    #changing to return only the count\n",
    "    return just_count\n",
    "    #return key_values\n",
    "            \n",
    "    \n",
    "def obtain_injured_numeric_value(doc):\n",
    "\n",
    "    key_values = []\n",
    "    just_count = []\n",
    "    \n",
    "    def check_flags(lst):\n",
    "        for l in lst:\n",
    "            if l == -1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    #doc = doc.tolist()[0]\n",
    "    attribute = -1\n",
    "    noun = -1\n",
    "    count = -1\n",
    "\n",
    "    for t in doc:\n",
    "        if str(t).isdigit():\n",
    "            count = t\n",
    "        if t in indicators['i_people']:\n",
    "            noun = t\n",
    "        if t in indicators['i_injured']:\n",
    "            attribute = t\n",
    "\n",
    "        if check_flags([noun,attribute,count]):\n",
    "\n",
    "            noun_att_cnt = (noun,attribute,count)\n",
    "            key_values.append(noun_att_cnt)\n",
    "            just_count.append(count)\n",
    "\n",
    "            noun = -1\n",
    "            attribute = -1\n",
    "            count = -1\n",
    "\n",
    "    #changing to return only the count\n",
    "    return just_count\n",
    "    #return key_values\n",
    "\n",
    "def obtain_counted_noun_chunks(doc):\n",
    "    counted_things = []\n",
    "    for x in list(extract.noun_chunks(doc)):\n",
    "        for token in x:\n",
    "            if str(token).isdigit():\n",
    "                counted_things.append(x)\n",
    "                continue\n",
    "    if len(counted_things) > 0:\n",
    "        return counted_things\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "\n",
    "def obtain_all_entities(doc):\n",
    "\n",
    "    STOP_ENTS = ['WASH','PSS','GTC','PFA','NFI','IYCF']\n",
    "    #stop_ents = STOP_ENTS\n",
    "    ents = list(extract.entities(doc))\n",
    "    if len(ents) < 1:\n",
    "        return None\n",
    "    entities = defaultdict(list) \n",
    "    for e in ents:\n",
    "        #if e.text not in stop_ents:\n",
    "        entities[e.label_].append(e)\n",
    "\n",
    "    return entities   \n",
    "\n",
    "def extract_entities(row):\n",
    "    entities = row['entities']\n",
    "    if entities is None:\n",
    "        return ''\n",
    "    en=[]\n",
    "    for label in entities:\n",
    "        for e in entities.get(label):\n",
    "            ent = ' '.join([w.text for w in e]).strip()\n",
    "            en.append([label,ent])\n",
    "            \n",
    "    return en\n",
    "\n",
    "\n",
    "def extract_ncs(row):\n",
    "    #data type, list of spans\n",
    "    xs = row['noun_chunks']\n",
    "    if xs is None:\n",
    "        return ''\n",
    "    en=[]\n",
    "\n",
    "    for e in xs:\n",
    "        ent = ' '.join([w.text for w in e]).strip()\n",
    "        en.append(['NOUN_CHUNK',ent])\n",
    "    return en\n",
    "\n",
    "\n",
    "def extract_numeric_key_values(row):\n",
    "    #data type, list of spans\n",
    "    xs = row['num_others']\n",
    "    if xs is None:\n",
    "        return ''\n",
    "    return_list=[]\n",
    "\n",
    "    for e in xs:\n",
    "        prefix = ''\n",
    "        numeric = ''\n",
    "        suffix = ''\n",
    "\n",
    "        for token in e:\n",
    "            if token.is_alpha == False:\n",
    "                numeric = token.text\n",
    "            elif numeric == '': #alpha but numeric not set yet, this is prefix\n",
    "                prefix = prefix + ' ' + token.text\n",
    "            else:\n",
    "                suffix = suffix + ' ' + token.text\n",
    "        \n",
    "        return_list.append([prefix.strip(),numeric,suffix.strip()])   \n",
    "        \n",
    "    return return_list\n",
    "\n",
    "\n",
    "def split_key_value_in_df(field,delim=','):\n",
    "\n",
    "    s = pd.Series({'prefix' : field, 'left_label' : field, 'right_label' : field})\n",
    "    \n",
    "    if isinstance(field, list):\n",
    "        fields = field\n",
    "    elif isinstance(field, str):\n",
    "        fields = field.split(delim)\n",
    "    else:\n",
    "        print(field)\n",
    "    \n",
    "     \n",
    "    if len(fields) == 2:\n",
    "        s = pd.Series({'prefix' : '', 'left_label' : fields[0], 'right_label' : fields[1]})\n",
    "    elif len(fields) == 3:\n",
    "        s = pd.Series({'prefix' : fields[0], 'left_label' : fields[1], 'right_label' : fields[2]})\n",
    "\n",
    "\n",
    "\n",
    "    return s\n",
    "\n",
    "def split_key_value_in_df_orig(field,left_label=\"d\",right_label=\"f\",delim=','):\n",
    "\n",
    "    s = pd.Series({left_label : field, right_label : field})\n",
    "    \n",
    "    if isinstance(field, list):\n",
    "     \n",
    "        if len(field) == 2:\n",
    "            s = pd.Series({left_label : field[0], right_label : field[1]})\n",
    "\n",
    "    elif isinstance(field, str):\n",
    "        fields = field.split(delim)\n",
    "        if len(fields) == 2:\n",
    "            s = pd.Series({left_label : fields[0], right_label : fields[1]})\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021d782-2fbb-4db6-afe1-913195073afa",
   "metadata": {},
   "source": [
    "## Now build base DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6183b2b6-a15f-4da2-b6c6-b8f17e4824d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_type</th>\n",
       "      <th>source_url</th>\n",
       "      <th>glide_id</th>\n",
       "      <th>source_level_country</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_desc</th>\n",
       "      <th>source_original_text</th>\n",
       "      <th>reference_url</th>\n",
       "      <th>text</th>\n",
       "      <th>authoring_org</th>\n",
       "      <th>reported_date</th>\n",
       "      <th>string_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>Multi-country outbreak of mpox (monkeypox) - E...</td>\n",
       "      <td>health</td>\n",
       "      <td>**Highlights**</td>\n",
       "      <td>https://reliefweb.int/attachments/2e5a83c9-d6f...</td>\n",
       "      <td>**Highlights**</td>\n",
       "      <td>WHO</td>\n",
       "      <td>2023-11-25T00:00:00+00:00</td>\n",
       "      <td>Highlights.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>Multi-country outbreak of mpox (monkeypox) - E...</td>\n",
       "      <td>health</td>\n",
       "      <td>- The mpox surveillance reporting frequency ha...</td>\n",
       "      <td>https://reliefweb.int/attachments/2e5a83c9-d6f...</td>\n",
       "      <td>- The mpox surveillance reporting frequency ha...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>2023-11-25T00:00:00+00:00</td>\n",
       "      <td>The mpox surveillance reporting frequency has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>Multi-country outbreak of mpox (monkeypox) - E...</td>\n",
       "      <td>health</td>\n",
       "      <td>- The mpox surveillance reporting frequency ha...</td>\n",
       "      <td>https://reliefweb.int/attachments/2e5a83c9-d6f...</td>\n",
       "      <td>- The mpox surveillance reporting frequency ha...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>2023-11-25T00:00:00+00:00</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>Multi-country outbreak of mpox (monkeypox) - E...</td>\n",
       "      <td>health</td>\n",
       "      <td>- A total of 668 new laboratory-confirmed case...</td>\n",
       "      <td>https://reliefweb.int/attachments/2e5a83c9-d6f...</td>\n",
       "      <td>- A total of 668 new laboratory-confirmed case...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>2023-11-25T00:00:00+00:00</td>\n",
       "      <td>A total of 668 new laboratoryconfirmed cases w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>Multi-country outbreak of mpox (monkeypox) - E...</td>\n",
       "      <td>health</td>\n",
       "      <td>- A total of 668 new laboratory-confirmed case...</td>\n",
       "      <td>https://reliefweb.int/attachments/2e5a83c9-d6f...</td>\n",
       "      <td>- A total of 668 new laboratory-confirmed case...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>2023-11-25T00:00:00+00:00</td>\n",
       "      <td>The most affected regions, ordered by number o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>EP-2023-000181-SDN</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>South Sudan: Response to the Sudan Crisis Situ...</td>\n",
       "      <td>contributions; coordination; food and nutritio...</td>\n",
       "      <td>- Currently, the onward transportation assista...</td>\n",
       "      <td>https://reliefweb.int/attachments/a94aa91b-f5d...</td>\n",
       "      <td>- Currently, the onward transportation assista...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-11-22T00:00:00+00:00</td>\n",
       "      <td>As a result, there are a backlog of people in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>EP-2023-000181-SDN</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>South Sudan: Response to the Sudan Crisis Situ...</td>\n",
       "      <td>contributions; coordination; food and nutritio...</td>\n",
       "      <td>- Currently, the onward transportation assista...</td>\n",
       "      <td>https://reliefweb.int/attachments/a94aa91b-f5d...</td>\n",
       "      <td>- Currently, the onward transportation assista...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-11-22T00:00:00+00:00</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>EP-2023-000181-SDN</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>South Sudan: Response to the Sudan Crisis Situ...</td>\n",
       "      <td>contributions; coordination; food and nutritio...</td>\n",
       "      <td>- The number of Sudanese refugees and asylum s...</td>\n",
       "      <td>https://reliefweb.int/attachments/a94aa91b-f5d...</td>\n",
       "      <td>- The number of Sudanese refugees and asylum s...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-11-22T00:00:00+00:00</td>\n",
       "      <td>The number of Sudanese refugees and asylum see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>EP-2023-000181-SDN</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>South Sudan: Response to the Sudan Crisis Situ...</td>\n",
       "      <td>contributions; coordination; food and nutritio...</td>\n",
       "      <td>- The number of Sudanese refugees and asylum s...</td>\n",
       "      <td>https://reliefweb.int/attachments/a94aa91b-f5d...</td>\n",
       "      <td>- The number of Sudanese refugees and asylum s...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-11-22T00:00:00+00:00</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>situation report</td>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>EP-2023-000181-SDN</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>South Sudan: Response to the Sudan Crisis Situ...</td>\n",
       "      <td>contributions; coordination; food and nutritio...</td>\n",
       "      <td>- Disruption of supply lines to Abyei Administ...</td>\n",
       "      <td>https://reliefweb.int/attachments/a94aa91b-f5d...</td>\n",
       "      <td>- Disruption of supply lines to Abyei Administ...</td>\n",
       "      <td>OCHA</td>\n",
       "      <td>2023-11-22T00:00:00+00:00</td>\n",
       "      <td>Disruption of supply lines to Abyei Administra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3356 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           record_type                                    source_url  \\\n",
       "0     situation report  https://api.reliefweb.int/v1/reports/4017691   \n",
       "1     situation report  https://api.reliefweb.int/v1/reports/4017691   \n",
       "2     situation report  https://api.reliefweb.int/v1/reports/4017691   \n",
       "3     situation report  https://api.reliefweb.int/v1/reports/4017691   \n",
       "4     situation report  https://api.reliefweb.int/v1/reports/4017691   \n",
       "...                ...                                           ...   \n",
       "3351  situation report  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3352  situation report  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3353  situation report  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3354  situation report  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3355  situation report  https://api.reliefweb.int/v1/reports/4016821   \n",
       "\n",
       "                glide_id source_level_country  \\\n",
       "0                    NaN                World   \n",
       "1                    NaN                World   \n",
       "2                    NaN                World   \n",
       "3                    NaN                World   \n",
       "4                    NaN                World   \n",
       "...                  ...                  ...   \n",
       "3351  EP-2023-000181-SDN          South Sudan   \n",
       "3352  EP-2023-000181-SDN          South Sudan   \n",
       "3353  EP-2023-000181-SDN          South Sudan   \n",
       "3354  EP-2023-000181-SDN          South Sudan   \n",
       "3355  EP-2023-000181-SDN          South Sudan   \n",
       "\n",
       "                                           source_title  \\\n",
       "0     Multi-country outbreak of mpox (monkeypox) - E...   \n",
       "1     Multi-country outbreak of mpox (monkeypox) - E...   \n",
       "2     Multi-country outbreak of mpox (monkeypox) - E...   \n",
       "3     Multi-country outbreak of mpox (monkeypox) - E...   \n",
       "4     Multi-country outbreak of mpox (monkeypox) - E...   \n",
       "...                                                 ...   \n",
       "3351  South Sudan: Response to the Sudan Crisis Situ...   \n",
       "3352  South Sudan: Response to the Sudan Crisis Situ...   \n",
       "3353  South Sudan: Response to the Sudan Crisis Situ...   \n",
       "3354  South Sudan: Response to the Sudan Crisis Situ...   \n",
       "3355  South Sudan: Response to the Sudan Crisis Situ...   \n",
       "\n",
       "                                            source_desc  \\\n",
       "0                                                health   \n",
       "1                                                health   \n",
       "2                                                health   \n",
       "3                                                health   \n",
       "4                                                health   \n",
       "...                                                 ...   \n",
       "3351  contributions; coordination; food and nutritio...   \n",
       "3352  contributions; coordination; food and nutritio...   \n",
       "3353  contributions; coordination; food and nutritio...   \n",
       "3354  contributions; coordination; food and nutritio...   \n",
       "3355  contributions; coordination; food and nutritio...   \n",
       "\n",
       "                                   source_original_text  \\\n",
       "0                                        **Highlights**   \n",
       "1     - The mpox surveillance reporting frequency ha...   \n",
       "2     - The mpox surveillance reporting frequency ha...   \n",
       "3     - A total of 668 new laboratory-confirmed case...   \n",
       "4     - A total of 668 new laboratory-confirmed case...   \n",
       "...                                                 ...   \n",
       "3351  - Currently, the onward transportation assista...   \n",
       "3352  - Currently, the onward transportation assista...   \n",
       "3353  - The number of Sudanese refugees and asylum s...   \n",
       "3354  - The number of Sudanese refugees and asylum s...   \n",
       "3355  - Disruption of supply lines to Abyei Administ...   \n",
       "\n",
       "                                          reference_url  \\\n",
       "0     https://reliefweb.int/attachments/2e5a83c9-d6f...   \n",
       "1     https://reliefweb.int/attachments/2e5a83c9-d6f...   \n",
       "2     https://reliefweb.int/attachments/2e5a83c9-d6f...   \n",
       "3     https://reliefweb.int/attachments/2e5a83c9-d6f...   \n",
       "4     https://reliefweb.int/attachments/2e5a83c9-d6f...   \n",
       "...                                                 ...   \n",
       "3351  https://reliefweb.int/attachments/a94aa91b-f5d...   \n",
       "3352  https://reliefweb.int/attachments/a94aa91b-f5d...   \n",
       "3353  https://reliefweb.int/attachments/a94aa91b-f5d...   \n",
       "3354  https://reliefweb.int/attachments/a94aa91b-f5d...   \n",
       "3355  https://reliefweb.int/attachments/a94aa91b-f5d...   \n",
       "\n",
       "                                                   text authoring_org  \\\n",
       "0                                        **Highlights**           WHO   \n",
       "1     - The mpox surveillance reporting frequency ha...           WHO   \n",
       "2     - The mpox surveillance reporting frequency ha...           WHO   \n",
       "3     - A total of 668 new laboratory-confirmed case...           WHO   \n",
       "4     - A total of 668 new laboratory-confirmed case...           WHO   \n",
       "...                                                 ...           ...   \n",
       "3351  - Currently, the onward transportation assista...          OCHA   \n",
       "3352  - Currently, the onward transportation assista...          OCHA   \n",
       "3353  - The number of Sudanese refugees and asylum s...          OCHA   \n",
       "3354  - The number of Sudanese refugees and asylum s...          OCHA   \n",
       "3355  - Disruption of supply lines to Abyei Administ...          OCHA   \n",
       "\n",
       "                  reported_date  \\\n",
       "0     2023-11-25T00:00:00+00:00   \n",
       "1     2023-11-25T00:00:00+00:00   \n",
       "2     2023-11-25T00:00:00+00:00   \n",
       "3     2023-11-25T00:00:00+00:00   \n",
       "4     2023-11-25T00:00:00+00:00   \n",
       "...                         ...   \n",
       "3351  2023-11-22T00:00:00+00:00   \n",
       "3352  2023-11-22T00:00:00+00:00   \n",
       "3353  2023-11-22T00:00:00+00:00   \n",
       "3354  2023-11-22T00:00:00+00:00   \n",
       "3355  2023-11-22T00:00:00+00:00   \n",
       "\n",
       "                                        string_sentence  \n",
       "0                                           Highlights.  \n",
       "1     The mpox surveillance reporting frequency has ...  \n",
       "2                                                     .  \n",
       "3     A total of 668 new laboratoryconfirmed cases w...  \n",
       "4     The most affected regions, ordered by number o...  \n",
       "...                                                 ...  \n",
       "3351  As a result, there are a backlog of people in ...  \n",
       "3352                                                  .  \n",
       "3353  The number of Sudanese refugees and asylum see...  \n",
       "3354                                                  .  \n",
       "3355  Disruption of supply lines to Abyei Administra...  \n",
       "\n",
       "[3356 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(situation_reports)\n",
    "df['string_sentence'] = df['text'].apply(lambda x: string_preprocess(x).split('.'))\n",
    "df = df.explode('string_sentence')\n",
    "df['string_sentence'] = df['string_sentence'].apply(lambda x: x.strip() + '.')\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e67eccd-1929-4b85-92b5-a419e39596a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ville de Bamako a hébergé l’atelier national du cycle de programmation humanitaire (HPC) pour l’année 2024. Cet exercice annuel a réuni les représentants des services étatiques, les acteurs humanitaires et du développement, et les donateurs autour de l’analyse conjointe des besoins humanitaires des populations vulnérables, ainsi que les réponses à apporter pour sauver des vies. Cet atelier, qui s’est tenu sur deux jours, a permis de définir les populations, les zones, ainsi que les secteurs d’interventions prioritaires du prochain Plan de Réponse Humanitaire de l’année 2024.  \n",
      "\n",
      "Cet exercice annuel a runi les reprsentants des services tatiques, les acteurs humanitaires et du dveloppement, et les donateurs autour de lanalyse conjointe des besoins humanitaires des populations vulnrables, ainsi que les rponses  apporter pour sauver des vies.\n"
     ]
    }
   ],
   "source": [
    "idx = df.sample(1).index[0]\n",
    "print(df.loc[idx]['source_original_text']) #.tolist()[0]\n",
    "print()\n",
    "print(df.loc[idx]['string_sentence']) #.tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2173564f-a0b3-4856-8d9b-da2bb23a1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b build out initial dataframe\n",
    "df['spacy_doc'] = df['string_sentence'].apply(lambda x: nlp(x))\n",
    "df['lower_lemmas'] = df['spacy_doc'].apply(lambda x: [w.lemma_.lower() for w in x])\n",
    "\n",
    "df['string_sent_wo_parens'] = df['string_sentence'].apply(string_remove_parenthetical_content)\n",
    "df['spacy_wo_parens'] = df['string_sent_wo_parens'].apply(lambda x: nlp(x))\n",
    "df['wo_parens_lower_lemmas'] = df['spacy_wo_parens'].apply(lambda x: [w.lemma_.lower() for w in x])\n",
    "df['locations'] = df['spacy_doc'].apply(lambda doc: [e.text for e in doc.ents if e.label_ == 'GPE'])\n",
    "df['dates'] = df['spacy_doc'].apply(lambda doc: [e.text for e in doc.ents if e.label_ == 'DATE'])\n",
    "df['svot'] = df['spacy_wo_parens'].apply(lambda doc: list(extract.subject_verb_object_triples(doc)))\n",
    "df['future_verbs'] = df['spacy_doc'].apply(get_future_tense_verb)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a008d4d5-e16c-44c7-b277-c06ac4fb7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_and_add_indicator(df, indicators)\n",
    "df['record_type'] = df.apply(declare_primary_record_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "298fe78b-a2b8-4b98-beb5-9358c3cf0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_killed'] = df['wo_parens_lower_lemmas'][df['i_killed'] == 1].apply(obtain_killed_numeric_value)\n",
    "df['num_injured'] = df['wo_parens_lower_lemmas'][df['i_injured'] == 1].apply(obtain_injured_numeric_value)\n",
    "df['num_others'] = df['spacy_wo_parens'].apply(obtain_counted_noun_chunks)\n",
    "df['noun_chunks'] = df['spacy_wo_parens'].apply(lambda doc: list(extract.noun_chunks(doc)))\n",
    "df['entities'] = df['spacy_wo_parens'].apply(obtain_all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b13c0f9-6439-4e74-9ec2-1a8f39ca18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid(x):\n",
    "    foo = uuid.uuid4().hex\n",
    "    return foo\n",
    "    \n",
    "df['sent_idx'] = df['sent_idx'].apply(generate_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65ee5310-a583-4f10-bdc4-b0ac0338a95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2f6a3718d850403dbb154f55c3ddd5f8\n",
       "1       77aa2570faf34a7aa28cf188f8aa1612\n",
       "2       90eea03650b44d5cae260937c6ebf76f\n",
       "3       2cdb73e9830142498ed9821a7381453c\n",
       "4       30026648414a4de7a02f0a0631279dfa\n",
       "                      ...               \n",
       "3351    bf46d33314734662bd5099c8e0f0174d\n",
       "3352    326faa0ad06c4f68ba36fb5bdf3ac07e\n",
       "3353    dcdbbebe724a4b25b6a7ed9fb6245b04\n",
       "3354    3d360ea807664028b217b55c30795649\n",
       "3355    8826eaa450aa4c8294fee6c8379c8887\n",
       "Name: sent_idx, Length: 3356, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sent_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5127499-47cc-4fbd-b701-8f25dcd6e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"c://temp//foo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "742feaf2-ca61-4a72-8337-d369b06cf3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use this as a repeatable-ish pattern for expanding on all the qualitative fields\n",
    "df_entities = df[['source_url','sent_idx','string_sentence','entities']][df['entities'].isna() == False].copy()\n",
    "df_entities['tmp'] = df_entities.apply(extract_entities, axis=1)\n",
    "df_entities = df_entities.drop(columns=['entities'])\n",
    "df_entities = df_entities.explode('tmp')\n",
    "df_entities['rec_type'] = 'ENTITY'\n",
    "df_entities[['rec_prefix','rec_key','rec_value']] = df_entities.apply(lambda x: split_key_value_in_df(x.tmp), axis=1)\n",
    "\n",
    "#now noun_chunks\n",
    "df_nouns = df[['source_url','sent_idx','string_sentence','noun_chunks']][df['noun_chunks'].isna() == False].copy()\n",
    "df_nouns['tmp'] = df_nouns.apply(extract_ncs, axis=1)\n",
    "df_nouns = df_nouns.drop(columns=['noun_chunks'])\n",
    "df_nouns = df_nouns.explode('tmp')\n",
    "df_nouns['rec_type'] = 'NOUN_SEQUENCE'\n",
    "df_nouns = df_nouns[df_nouns['tmp'].isna() == False].copy()\n",
    "df_nouns[['rec_prefix','rec_key','rec_value']] = df_nouns.apply(lambda x: split_key_value_in_df(x.tmp), axis=1)\n",
    "\n",
    "#quantitative values\n",
    "df_quants = df[['source_url','sent_idx','string_sentence','num_others']][df['num_others'] != ''].copy()\n",
    "df_quants['tmp'] = df_quants.apply(extract_numeric_key_values, axis=1)\n",
    "df_quants = df_quants.drop(columns=['num_others'])\n",
    "df_quants = df_quants.explode('tmp')\n",
    "df_quants['rec_type'] = 'QUANTIFIED_NOUN'\n",
    "df_quants[['rec_prefix','rec_key','rec_value']] = df_quants.apply(lambda x: split_key_value_in_df(x.tmp), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd7c520e-e9a4-4926-b6f2-a9e704056638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>string_sentence</th>\n",
       "      <th>rec_type</th>\n",
       "      <th>rec_prefix</th>\n",
       "      <th>rec_key</th>\n",
       "      <th>rec_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>2cdb73e9830142498ed9821a7381453c</td>\n",
       "      <td>A total of 668 new laboratoryconfirmed cases w...</td>\n",
       "      <td>QUANTIFIED_NOUN</td>\n",
       "      <td></td>\n",
       "      <td>668</td>\n",
       "      <td>new laboratoryconfirmed cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>2cdb73e9830142498ed9821a7381453c</td>\n",
       "      <td>A total of 668 new laboratoryconfirmed cases w...</td>\n",
       "      <td>QUANTIFIED_NOUN</td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "      <td>countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>671d84cf04e24b0e93f922a2cb305646</td>\n",
       "      <td>Eight laboratoryconfirmed cases were reported ...</td>\n",
       "      <td>QUANTIFIED_NOUN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017691</td>\n",
       "      <td>cff07493847140c1960b49d1fc7bf0ec</td>\n",
       "      <td>This summary highlights the reporting since 1 ...</td>\n",
       "      <td>QUANTIFIED_NOUN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4017686</td>\n",
       "      <td>e267fabf2f8c4d6a88b2b5771d246358</td>\n",
       "      <td>A total of 8287 individuals have fled Jilib an...</td>\n",
       "      <td>QUANTIFIED_NOUN</td>\n",
       "      <td></td>\n",
       "      <td>8287</td>\n",
       "      <td>individuals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>dcdbbebe724a4b25b6a7ed9fb6245b04</td>\n",
       "      <td>The number of Sudanese refugees and asylum see...</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td></td>\n",
       "      <td>PERSON</td>\n",
       "      <td>WunthowJoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>dcdbbebe724a4b25b6a7ed9fb6245b04</td>\n",
       "      <td>The number of Sudanese refugees and asylum see...</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td></td>\n",
       "      <td>DATE</td>\n",
       "      <td>previous weeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>8826eaa450aa4c8294fee6c8379c8887</td>\n",
       "      <td>Disruption of supply lines to Abyei Administra...</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td></td>\n",
       "      <td>ORG</td>\n",
       "      <td>Abyei Administrative Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>8826eaa450aa4c8294fee6c8379c8887</td>\n",
       "      <td>Disruption of supply lines to Abyei Administra...</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td></td>\n",
       "      <td>GPE</td>\n",
       "      <td>Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>https://api.reliefweb.int/v1/reports/4016821</td>\n",
       "      <td>8826eaa450aa4c8294fee6c8379c8887</td>\n",
       "      <td>Disruption of supply lines to Abyei Administra...</td>\n",
       "      <td>ENTITY</td>\n",
       "      <td></td>\n",
       "      <td>GPE</td>\n",
       "      <td>South Sudan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        source_url  \\\n",
       "3     https://api.reliefweb.int/v1/reports/4017691   \n",
       "3     https://api.reliefweb.int/v1/reports/4017691   \n",
       "6     https://api.reliefweb.int/v1/reports/4017691   \n",
       "11    https://api.reliefweb.int/v1/reports/4017691   \n",
       "19    https://api.reliefweb.int/v1/reports/4017686   \n",
       "...                                            ...   \n",
       "3353  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3353  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3355  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3355  https://api.reliefweb.int/v1/reports/4016821   \n",
       "3355  https://api.reliefweb.int/v1/reports/4016821   \n",
       "\n",
       "                              sent_idx  \\\n",
       "3     2cdb73e9830142498ed9821a7381453c   \n",
       "3     2cdb73e9830142498ed9821a7381453c   \n",
       "6     671d84cf04e24b0e93f922a2cb305646   \n",
       "11    cff07493847140c1960b49d1fc7bf0ec   \n",
       "19    e267fabf2f8c4d6a88b2b5771d246358   \n",
       "...                                ...   \n",
       "3353  dcdbbebe724a4b25b6a7ed9fb6245b04   \n",
       "3353  dcdbbebe724a4b25b6a7ed9fb6245b04   \n",
       "3355  8826eaa450aa4c8294fee6c8379c8887   \n",
       "3355  8826eaa450aa4c8294fee6c8379c8887   \n",
       "3355  8826eaa450aa4c8294fee6c8379c8887   \n",
       "\n",
       "                                        string_sentence         rec_type  \\\n",
       "3     A total of 668 new laboratoryconfirmed cases w...  QUANTIFIED_NOUN   \n",
       "3     A total of 668 new laboratoryconfirmed cases w...  QUANTIFIED_NOUN   \n",
       "6     Eight laboratoryconfirmed cases were reported ...  QUANTIFIED_NOUN   \n",
       "11    This summary highlights the reporting since 1 ...  QUANTIFIED_NOUN   \n",
       "19    A total of 8287 individuals have fled Jilib an...  QUANTIFIED_NOUN   \n",
       "...                                                 ...              ...   \n",
       "3353  The number of Sudanese refugees and asylum see...           ENTITY   \n",
       "3353  The number of Sudanese refugees and asylum see...           ENTITY   \n",
       "3355  Disruption of supply lines to Abyei Administra...           ENTITY   \n",
       "3355  Disruption of supply lines to Abyei Administra...           ENTITY   \n",
       "3355  Disruption of supply lines to Abyei Administra...           ENTITY   \n",
       "\n",
       "     rec_prefix rec_key                      rec_value  \n",
       "3                   668  new laboratoryconfirmed cases  \n",
       "3                    29                      countries  \n",
       "6                     1                           case  \n",
       "11                    1                        January  \n",
       "19                 8287                    individuals  \n",
       "...         ...     ...                            ...  \n",
       "3353             PERSON                    WunthowJoda  \n",
       "3353               DATE                 previous weeks  \n",
       "3355                ORG      Abyei Administrative Area  \n",
       "3355                GPE                          Sudan  \n",
       "3355                GPE                    South Sudan  \n",
       "\n",
       "[20608 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes = pd.concat([df_quants, df_nouns,df_entities])\n",
    "df_attributes = df_attributes.drop(columns=['tmp'])\n",
    "df_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb32b4be-93e9-4779-9713-22c3b825dcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21322, 54)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join base and attribute df\n",
    "df_joined = df.merge(df_attributes[['sent_idx','rec_type','rec_prefix','rec_key','rec_value']], left_on='sent_idx', right_on='sent_idx', how='left').copy()\n",
    "df_joined.explode('locations')\n",
    "df_joined['locations'] = df_joined['locations'].apply(lambda x: x[0] if len(x)==1 else '')\n",
    "df_joined.explode('dates')\n",
    "df_joined['dates'] = df_joined['dates'].apply(lambda x: x[0] if len(x)==1 else '')\n",
    "\n",
    "\n",
    "df_joined.explode('svot')\n",
    "df_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187ad6a-2b12-4fad-b94b-1b231c1d4b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
